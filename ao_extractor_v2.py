"""
ğŸš€ AOExtractor V2 - Architecture Modulaire
==========================================

Version refactorisÃ©e du AOExtractor utilisant l'architecture modulaire.
Remplace l'ancien ao_extractor.py avec une approche plus maintenable.
"""

import pandas as pd
import logging
import time
import traceback
from typing import Dict, Any, List, Optional, Union
from datetime import datetime
import os

# Import des modules modulaires
from extractors import (
    PatternManager, ValidationEngine, PDFExtractor, 
    ExcelExtractor, TextExtractor, LotDetector
)
from extractors.file_type_detector import FileTypeDetector
from extractors.intelligent_post_processor import IntelligentPostProcessor
from extractors.database_context_learner import DatabaseContextLearner

logger = logging.getLogger(__name__)

class AOExtractorV2:
    """
    Extracteur d'Appels d'Offres V2 - Architecture Modulaire
    
    Version refactorisÃ©e utilisant une architecture modulaire pour une meilleure
    maintenabilitÃ©, performance et extensibilitÃ©.
    """
    
    def __init__(self, reference_data: pd.DataFrame = None, database_manager=None):
        """
        Initialise l'extracteur V2
        
        Args:
            reference_data: DataFrame de rÃ©fÃ©rence pour l'apprentissage (optionnel)
            database_manager: Instance de DatabaseManager pour apprendre depuis la BDD (optionnel)
        """
        self.reference_data = reference_data
        self.database_manager = database_manager
        
        # Initialiser les composants modulaires
        self.pattern_manager = PatternManager()
        self.validation_engine = ValidationEngine()
        self.lot_detector = LotDetector()
        
        # Initialiser l'apprenant contextuel depuis la BDD
        self.database_learner = DatabaseContextLearner(database_manager)
        if database_manager:
            # Apprendre depuis la BDD de maniÃ¨re asynchrone pour ne pas bloquer
            try:
                self.database_learner.learn_from_database(limit=500)
                logger.info("âœ… Apprentissage depuis la base de donnÃ©es terminÃ©")
            except Exception as e:
                logger.warning(f"âš ï¸ Erreur apprentissage BDD: {e}")
        
        # Initialiser les extracteurs spÃ©cialisÃ©s
        self.pdf_extractor = PDFExtractor(self.pattern_manager, self.validation_engine)
        self.excel_extractor = ExcelExtractor(self.pattern_manager, self.validation_engine)
        self.text_extractor = TextExtractor(self.pattern_manager, self.validation_engine)
        
        # Passer le database_learner aux extracteurs pour la gÃ©nÃ©ration intelligente
        if self.database_learner:
            self.pdf_extractor.database_learner = self.database_learner
            self.excel_extractor.database_learner = self.database_learner
            self.text_extractor.database_learner = self.database_learner
        
        # Initialiser le dÃ©tecteur de type de fichier unifiÃ©
        self.file_type_detector = FileTypeDetector
        
        # Initialiser le post-processeur intelligent
        self.intelligent_processor = IntelligentPostProcessor(enable_improver=True)
        
        # MÃ©triques de performance amÃ©liorÃ©es
        self.performance_metrics = {
            'total_extractions': 0,
            'successful_extractions': 0,
            'extraction_errors': 0,
            'average_extraction_time': 0.0,
            'extraction_by_type': {
                'pdf': 0,
                'excel': 0,
                'text': 0,
                'other': 0
            },
            'errors_by_type': {},
            'extraction_time_by_type': {
                'pdf': [],
                'excel': [],
                'text': [],
                'other': []
            },
            'field_extraction_stats': {},
            'validation_failure_reasons': {}
        }
        
        # Apprentissage depuis les donnÃ©es de rÃ©fÃ©rence
        if self.reference_data is not None and not self.reference_data.empty:
            self._learn_from_reference_data()
        # Note: L'apprentissage depuis la BDD est dÃ©jÃ  fait au-dessus si database_manager est fourni
        
        logger.info("ğŸš€ AOExtractor V2 initialisÃ© avec architecture modulaire")
    
    def extract_from_file(self, uploaded_file, file_analysis: Dict[str, Any], target_columns: List[str] = None) -> List[Dict[str, Any]]:
        """
        Extrait les informations d'un appel d'offres depuis un fichier uploadÃ©
        
        Args:
            uploaded_file: Fichier uploadÃ© par l'utilisateur
            file_analysis: Analyse prÃ©liminaire du fichier
            target_columns: Liste des colonnes cibles de la base de donnÃ©es
            
        Returns:
            Liste des donnÃ©es extraites
        """
        start_time = time.time()
        
        try:
            self.performance_metrics['total_extractions'] += 1
            logger.info(f"ğŸ“ Extraction depuis le fichier: {uploaded_file.name}")
            
            # DÃ©terminer le type de fichier avec le dÃ©tecteur unifiÃ©
            file_type = self.file_type_detector.detect(
                file_name=uploaded_file.name,
                file_analysis=file_analysis
            )
            logger.info(f"ğŸ“‹ Type de fichier dÃ©tectÃ©: {file_type}")
            
            extractor = self._get_extractor_for_type(file_type)
            
            if not extractor:
                logger.error(f"âŒ Type de fichier non supportÃ©: {file_type}")
                return [{'erreur': f"Type de fichier non supportÃ©: {file_type}"}]
            
            # Logger l'extracteur utilisÃ©
            extractor_name = extractor.__class__.__name__
            logger.info(f"ğŸ”§ Utilisation de l'extracteur: {extractor_name}")
            
            # Effectuer l'extraction
            extracted_entries = extractor.extract(uploaded_file, file_analysis=file_analysis)
            logger.info(f"âœ… Extraction terminÃ©e avec {extractor_name}: {len(extracted_entries) if extracted_entries else 0} entrÃ©e(s)")
            
            if not extracted_entries:
                logger.warning("âš ï¸ Aucune donnÃ©e extraite")
                return []
            
            # Filtrer les colonnes cibles si spÃ©cifiÃ©es
            if target_columns:
                extracted_entries = self._filter_target_columns(extracted_entries, target_columns)
            
            # Mettre Ã  jour les mÃ©triques
            self.performance_metrics['successful_extractions'] += 1
            self.performance_metrics['extraction_by_type'][file_type] += 1
            
            # Calculer le temps d'extraction
            extraction_time = time.time() - start_time
            
            # Mettre Ã  jour le temps moyen
            if self.performance_metrics['total_extractions'] > 0:
                self.performance_metrics['average_extraction_time'] = (
                    (self.performance_metrics['average_extraction_time'] * 
                     (self.performance_metrics['total_extractions'] - 1) + extraction_time) /
                    self.performance_metrics['total_extractions']
                )
            else:
                self.performance_metrics['average_extraction_time'] = extraction_time
            
            # Enregistrer le temps par type
            if file_type in self.performance_metrics['extraction_time_by_type']:
                self.performance_metrics['extraction_time_by_type'][file_type].append(extraction_time)
            
            # Enrichir avec le post-processeur intelligent (si activÃ©)
            if self.intelligent_processor.is_available() and extracted_entries:
                for entry in extracted_entries:
                    if 'valeurs_extraites' in entry:
                        # RÃ©cupÃ©rer le texte source si disponible
                        text_source = entry.get('text_source', '')
                        if text_source:
                            enhanced_data = self.intelligent_processor.enhance_extraction(
                                entry['valeurs_extraites'],
                                text_source,
                                context=file_analysis
                            )
                            entry['valeurs_extraites'] = enhanced_data
            
            # Enrichir avec les suggestions depuis la base de donnÃ©es
            if self.database_learner and self.database_learner.is_trained:
                for entry in extracted_entries:
                    if 'valeurs_extraites' in entry:
                        self._enrich_with_database_suggestions(entry['valeurs_extraites'])
            
            # Les valeurs gÃ©nÃ©rÃ©es (segment, famille) sont dÃ©jÃ  crÃ©Ã©es dans generate_missing_values()
            # via les mÃ©thodes _classify_segment() et _classify_famille() qui utilisent database_learner
            
            logger.info(f"âœ… Extraction terminÃ©e: {len(extracted_entries)} entrÃ©es en {extraction_time:.2f}s")
            return extracted_entries
            
        except Exception as e:
            self.performance_metrics['extraction_errors'] += 1
            error_type = type(e).__name__
            
            # Logger avec traceback pour debug
            logger.error(
                f"âŒ Erreur lors de l'extraction ({error_type}): {e}\n"
                f"Traceback: {traceback.format_exc()}"
            )
            
            # Mettre Ã  jour les mÃ©triques d'erreur par type
            if 'errors_by_type' not in self.performance_metrics:
                self.performance_metrics['errors_by_type'] = {}
            self.performance_metrics['errors_by_type'][error_type] = \
                self.performance_metrics['errors_by_type'].get(error_type, 0) + 1
            
            return [{
                'erreur': f"Erreur lors de l'extraction: {error_type} - {str(e)}",
                'error_type': error_type,
                'error_details': str(e)
            }]
    
    
    def _get_extractor_for_type(self, file_type: str):
        """
        Retourne l'extracteur appropriÃ© pour le type de fichier
        
        Args:
            file_type: Type de fichier
            
        Returns:
            Extracteur appropriÃ© ou None
        """
        extractors = {
            'pdf': self.pdf_extractor,
            'excel': self.excel_extractor,
            'text': self.text_extractor
        }
        
        return extractors.get(file_type)
    
    def _filter_target_columns(self, extracted_entries: List[Dict[str, Any]], target_columns: List[str]) -> List[Dict[str, Any]]:
        """
        Filtre les entrÃ©es pour ne garder que les colonnes cibles
        
        Args:
            extracted_entries: EntrÃ©es extraites
            target_columns: Colonnes cibles
            
        Returns:
            EntrÃ©es filtrÃ©es
        """
        try:
            filtered_entries = []
            
            for entry in extracted_entries:
                if 'valeurs_extraites' in entry:
                    # Filtrer les valeurs extraites
                    filtered_values = {}
                    for col in target_columns:
                        if col in entry['valeurs_extraites']:
                            filtered_values[col] = entry['valeurs_extraites'][col]
                    
                    # CrÃ©er une nouvelle entrÃ©e avec les valeurs filtrÃ©es
                    filtered_entry = entry.copy()
                    filtered_entry['valeurs_extraites'] = filtered_values
                    filtered_entries.append(filtered_entry)
                else:
                    # Garder l'entrÃ©e telle quelle si pas de valeurs_extraites
                    filtered_entries.append(entry)
            
            logger.info(f"ğŸ“Š Filtrage terminÃ©: {len(filtered_entries)} entrÃ©es filtrÃ©es")
            return filtered_entries
            
        except Exception as e:
            logger.error(f"Erreur filtrage colonnes cibles: {e}")
            return extracted_entries
    
    def validate_extraction(self, data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        Valide une extraction
        
        Args:
            data: DonnÃ©es Ã  valider
            
        Returns:
            RÃ©sultat de validation ou None
        """
        try:
            return self.validation_engine.validate_extraction(data)
        except Exception as e:
            logger.error(f"Erreur validation extraction: {e}")
            return None
    
    def get_patterns_for_field(self, field_name: str) -> List[str]:
        """
        RÃ©cupÃ¨re les patterns pour un champ
        
        Args:
            field_name: Nom du champ
            
        Returns:
            Liste des patterns
        """
        try:
            return self.pattern_manager.get_field_patterns(field_name)
        except Exception as e:
            logger.error(f"Erreur rÃ©cupÃ©ration patterns pour {field_name}: {e}")
            return []
    
    def add_custom_pattern(self, category: str, subcategory: str, pattern: str):
        """
        Ajoute un pattern personnalisÃ©
        
        Args:
            category: CatÃ©gorie du pattern
            subcategory: Sous-catÃ©gorie du pattern
            pattern: Pattern regex
        """
        try:
            self.pattern_manager.add_pattern(category, subcategory, pattern)
            logger.info(f"Pattern personnalisÃ© ajoutÃ©: {category}.{subcategory}")
        except Exception as e:
            logger.error(f"Erreur ajout pattern personnalisÃ©: {e}")
    
    def detect_lots(self, text: str) -> List[Dict[str, Any]]:
        """
        DÃ©tecte les lots dans un texte
        
        Args:
            text: Texte Ã  analyser
            
        Returns:
            Liste des lots dÃ©tectÃ©s
        """
        try:
            lots = self.lot_detector.detect_lots(text)
            return [lot.__dict__ for lot in lots]
        except Exception as e:
            logger.error(f"Erreur dÃ©tection lots: {e}")
            return []
    
    def get_performance_metrics(self) -> Dict[str, Any]:
        """
        Retourne les mÃ©triques de performance
        
        Returns:
            Dictionnaire des mÃ©triques
        """
        metrics = self.performance_metrics.copy()
        
        # Ajouter les mÃ©triques des composants
        metrics['pattern_manager'] = self.pattern_manager.get_performance_stats()
        metrics['validation_engine'] = self.validation_engine.get_performance_metrics()
        metrics['lot_detector'] = self.lot_detector.get_performance_metrics()
        
        return metrics
    
    def reset_metrics(self):
        """Remet Ã  zÃ©ro toutes les mÃ©triques"""
        self.performance_metrics = {
            'total_extractions': 0,
            'successful_extractions': 0,
            'extraction_errors': 0,
            'average_extraction_time': 0.0,
            'extraction_by_type': {
                'pdf': 0,
                'excel': 0,
                'text': 0,
                'other': 0
            },
            'errors_by_type': {},
            'extraction_time_by_type': {
                'pdf': [],
                'excel': [],
                'text': [],
                'other': []
            },
            'field_extraction_stats': {},
            'validation_failure_reasons': {}
        }
        
        self.pattern_manager.reset_stats()
        self.validation_engine.reset_metrics()
        self.lot_detector.reset_metrics()
        
        logger.info("ğŸ“Š MÃ©triques remises Ã  zÃ©ro")
    
    def _learn_from_reference_data(self):
        """
        Apprend des patterns depuis les donnÃ©es de rÃ©fÃ©rence
        
        Analyse les donnÃ©es existantes pour extraire des patterns communs
        et amÃ©liorer la dÃ©tection future.
        Si une DatabaseManager est disponible, utilise aussi les donnÃ©es de la BDD.
        """
        try:
            if self.reference_data is None or self.reference_data.empty:
                # Si pas de reference_data mais qu'on a un database_manager, l'utiliser
                if self.database_manager and not self.database_learner.is_trained:
                    logger.info("ğŸ“Š Pas de reference_data, utilisation directe de la BDD...")
                    self.database_learner.learn_from_database(limit=500)
                return
            
            logger.info(f"ğŸ§  Apprentissage depuis {len(self.reference_data)} enregistrements de rÃ©fÃ©rence...")
            
            # Analyser les intitulÃ©s de lots pour extraire des patterns
            if 'intitule_lot' in self.reference_data.columns:
                lots = self.reference_data['intitule_lot'].dropna()
                if not lots.empty:
                    common_words = self._extract_common_words(lots)
                    logger.info(f"ğŸ“Š {len(common_words)} mots communs extraits depuis les intitulÃ©s de lots")
            
            # Analyser les montants pour dÃ©tecter des patterns
            if 'montant_global_estime' in self.reference_data.columns:
                montants = self.reference_data['montant_global_estime'].dropna()
                if not montants.empty:
                    montant_stats = {
                        'min': float(montants.min()),
                        'max': float(montants.max()),
                        'mean': float(montants.mean()),
                        'median': float(montants.median())
                    }
                    logger.info(f"ğŸ’° Statistiques montants: {montant_stats}")
            
            # Si on a aussi un database_manager, fusionner les apprentissages
            if self.database_manager and not self.database_learner.is_trained:
                logger.info("ğŸ“Š Enrichissement avec les donnÃ©es de la BDD...")
                self.database_learner.learn_from_database(limit=500)
            
            logger.info("âœ… Apprentissage terminÃ©")
            
        except Exception as e:
            logger.warning(f"âš ï¸ Erreur lors de l'apprentissage: {e}")
    
    def _enrich_with_database_suggestions(self, extracted_data: Dict[str, Any]):
        """
        Enrichit les donnÃ©es extraites avec des suggestions depuis la BDD
        NE REMPLACE QUE LES CHAMPS VRAIMENT VIDES - ne modifie pas les valeurs extraites
        
        Args:
            extracted_data: DonnÃ©es extraites Ã  enrichir (modifiÃ© sur place)
        """
        try:
            if not self.database_learner or not self.database_learner.is_trained:
                return
            
            # Champs Ã  enrichir UNIQUEMENT si complÃ¨tement manquants ou vides
            # Note: segment et famille sont maintenant gÃ©nÃ©rÃ©s intelligemment dans generate_missing_values()
            fields_to_enrich = ['type_procedure', 'mono_multi', 'univers', 'groupement']
            
            for field in fields_to_enrich:
                # VÃ©rifier si le champ est vraiment vide (pas prÃ©sent, None, ou chaÃ®ne vide)
                current_value = extracted_data.get(field)
                
                if not current_value or (isinstance(current_value, str) and current_value.strip() == ''):
                    # SuggÃ©rer une valeur depuis la BDD
                    suggestion = self.database_learner.suggest_value(field, extracted_data)
                    if suggestion:
                        extracted_data[field] = suggestion
                        logger.debug(f"ğŸ’¡ Valeur suggÃ©rÃ©e depuis BDD pour {field}: {suggestion}")
                else:
                    # Le champ a dÃ©jÃ  une valeur - NE PAS la remplacer
                    logger.debug(f"âœ“ Champ '{field}' dÃ©jÃ  rempli ({current_value}), pas de suggestion")
        
        except Exception as e:
            logger.warning(f"âš ï¸ Erreur enrichissement avec suggestions BDD: {e}")
    
    def _extract_common_words(self, series: pd.Series, min_occurrences: int = 3) -> List[str]:
        """
        Extrait les mots communs d'une sÃ©rie de textes
        
        Args:
            series: SÃ©rie de textes Ã  analyser
            min_occurrences: Nombre minimum d'occurrences pour Ãªtre considÃ©rÃ© comme commun
            
        Returns:
            Liste des mots communs
        """
        try:
            from collections import Counter
            import re
            
            # Joindre tous les textes
            all_text = ' '.join(series.astype(str)).lower()
            
            # Extraire les mots (au moins 3 caractÃ¨res)
            words = re.findall(r'\b[a-zA-ZÃ€-Ã¿]{3,}\b', all_text)
            
            # Compter les occurrences
            word_counts = Counter(words)
            
            # Filtrer par nombre minimum d'occurrences
            common_words = [
                word for word, count in word_counts.items() 
                if count >= min_occurrences
            ]
            
            return sorted(common_words, key=lambda x: word_counts[x], reverse=True)[:50]
            
        except Exception as e:
            logger.error(f"Erreur extraction mots communs: {e}")
            return []
    
    def save_patterns_config(self, config_file: str):
        """
        Sauvegarde la configuration des patterns
        
        Args:
            config_file: Chemin du fichier de configuration
        """
        try:
            self.pattern_manager.save_to_file(config_file)
            logger.info(f"Configuration patterns sauvegardÃ©e: {config_file}")
        except Exception as e:
            logger.error(f"Erreur sauvegarde configuration: {e}")
    
    def load_patterns_config(self, config_file: str):
        """
        Charge la configuration des patterns
        
        Args:
            config_file: Chemin du fichier de configuration
        """
        try:
            self.pattern_manager.load_from_file(config_file)
            logger.info(f"Configuration patterns chargÃ©e: {config_file}")
        except Exception as e:
            logger.error(f"Erreur chargement configuration: {e}")
    
    def get_extraction_summary(self) -> Dict[str, Any]:
        """
        Retourne un rÃ©sumÃ© de l'extraction
        
        Returns:
            RÃ©sumÃ© de l'extraction
        """
        metrics = self.get_performance_metrics()
        
        return {
            'total_extractions': metrics['total_extractions'],
            'success_rate': (
                metrics['successful_extractions'] / metrics['total_extractions'] * 100
                if metrics['total_extractions'] > 0 else 0
            ),
            'average_time': metrics['average_extraction_time'],
            'extraction_by_type': metrics['extraction_by_type'],
            'pattern_compilations': metrics['pattern_manager']['total_compilations'],
            'validation_success_rate': (
                metrics['validation_engine']['successful_validations'] / 
                metrics['validation_engine']['total_validations'] * 100
                if metrics['validation_engine']['total_validations'] > 0 else 0
            ),
            'lot_detection_success_rate': (
                metrics['lot_detector']['successful_detections'] / 
                metrics['lot_detector']['total_detections'] * 100
                if metrics['lot_detector']['total_detections'] > 0 else 0
            )
        }
    
    def __str__(self) -> str:
        """ReprÃ©sentation string de l'extracteur"""
        metrics = self.get_performance_metrics()
        return f"AOExtractorV2(extractions={metrics['total_extractions']}, success_rate={self.get_extraction_summary()['success_rate']:.1f}%)"
    
    def __repr__(self) -> str:
        """ReprÃ©sentation dÃ©taillÃ©e de l'extracteur"""
        return f"AOExtractorV2(pattern_manager={self.pattern_manager}, validation_engine={self.validation_engine})"

"""
üìÑ Extracteur PDF - Sp√©cialis√©
=============================

Extracteur sp√©cialis√© pour les documents PDF d'appels d'offres.
Utilise le d√©tecteur de lots et les patterns modulaires.
"""

import logging
import re
import traceback
from io import BytesIO
from typing import Dict, Any, List, Optional
from .base_extractor import BaseExtractor
from .pattern_manager import PatternManager
from .lot_detector import LotDetector, LotInfo
from .validation_engine import ValidationEngine

logger = logging.getLogger(__name__)

class PDFExtractor(BaseExtractor):
    """Extracteur sp√©cialis√© pour les documents PDF"""
    
    def __init__(self, pattern_manager: PatternManager = None, validation_engine: ValidationEngine = None):
        """
        Initialise l'extracteur PDF
        
        Args:
            pattern_manager: Gestionnaire de patterns (optionnel)
            validation_engine: Moteur de validation (optionnel)
        """
        super().__init__(pattern_manager, validation_engine)
        self.lot_detector = LotDetector()
        self.pattern_manager = pattern_manager or PatternManager()
        self.validation_engine = validation_engine or ValidationEngine()
    
    def extract(self, source: Any, **kwargs) -> List[Dict[str, Any]]:
        """
        Extrait les donn√©es d'un document PDF
        
        Args:
            source: Source de donn√©es (fichier PDF, texte extrait, etc.)
            **kwargs: Arguments suppl√©mentaires
            
        Returns:
            Liste des donn√©es extraites
        """
        try:
            logger.info("üìÑ D√©but de l'extraction PDF...")
            
            # Extraire le texte du PDF
            text_content = self._extract_text_from_pdf(source)
            if not text_content:
                logger.warning("‚ö†Ô∏è Aucun contenu texte extrait du PDF")
                return []
            
            # D√©tecter les lots
            lots_detected = self.lot_detector.detect_lots(text_content)
            
            if lots_detected:
                logger.info(f"‚úÖ {len(lots_detected)} lots d√©tect√©s dans le PDF")
                return self._create_entries_for_lots(lots_detected, text_content)
            else:
                logger.info("‚ö†Ô∏è Aucun lot d√©tect√©, extraction standard")
                return self._extract_single_entry(text_content)
                
        except Exception as e:
            error_type = type(e).__name__
            logger.error(
                f"‚ùå Erreur extraction PDF ({error_type}): {e}\n"
                f"Traceback: {traceback.format_exc()}"
            )
            return [{
                'erreur': f"Erreur extraction PDF: {error_type} - {str(e)}",
                'error_type': error_type,
                'error_details': str(e)
            }]
    
    def _extract_text_from_pdf(self, source: Any) -> str:
        """
        Extrait le texte d'un PDF
        
        Args:
            source: Source PDF (fichier, bytes, etc.)
            
        Returns:
            Texte extrait
        """
        try:
            # Si c'est d√©j√† du texte, le retourner
            if isinstance(source, str):
                return source
            
            # Si c'est un fichier upload√© (Streamlit)
            if hasattr(source, 'read'):
                # Sauvegarder la position actuelle
                try:
                    current_pos = source.tell()
                except:
                    current_pos = 0
                
                # R√©initialiser √† la position 0 si n√©cessaire
                try:
                    if current_pos > 0:
                        source.seek(0)
                except:
                    pass
                
                # Lire le contenu du fichier
                try:
                    content = source.read()
                    # R√©initialiser apr√®s lecture pour permettre une r√©utilisation
                    try:
                        source.seek(0)
                    except:
                        pass
                    
                    if isinstance(content, bytes):
                        # Utiliser PyPDF2 ou pdfplumber pour extraire le texte
                        return self._extract_text_from_bytes(content)
                    else:
                        return str(content)
                except Exception as e:
                    logger.error(f"Erreur lecture fichier: {e}")
                    return ""
            
            # Si c'est un dictionnaire avec le contenu extrait
            if isinstance(source, dict) and 'text_content' in source:
                return source['text_content']
            
            # Si c'est une liste de pages
            if isinstance(source, list):
                return '\n'.join(str(page) for page in source)
            
            return str(source)
            
        except Exception as e:
            error_type = type(e).__name__
            logger.error(
                f"‚ùå Erreur extraction texte PDF ({error_type}): {e}\n"
                f"Traceback: {traceback.format_exc()}"
            )
            return ""
    
    def _extract_text_from_bytes(self, pdf_bytes: bytes) -> str:
        """
        Extrait le texte depuis des bytes PDF avec support OCR pour PDFs scann√©s
        
        Args:
            pdf_bytes: Contenu PDF en bytes
            
        Returns:
            Texte extrait
        """
        try:
            # Essayer d'abord avec PyPDF2
            try:
                import PyPDF2
                
                pdf_file = BytesIO(pdf_bytes)
                pdf_reader = PyPDF2.PdfReader(pdf_file)
                
                text = ""
                for page in pdf_reader.pages:
                    text += page.extract_text() + "\n"
                
                if text.strip() and len(text.strip()) > 100:
                    logger.info("‚úÖ Texte extrait avec PyPDF2")
                    return text
                    
            except ImportError:
                logger.warning("PyPDF2 non disponible")
            except Exception as e:
                logger.warning(f"Erreur PyPDF2: {e}")
            
            # Essayer avec pdfplumber
            try:
                import pdfplumber
                
                with pdfplumber.open(BytesIO(pdf_bytes)) as pdf:
                    text = ""
                    for page in pdf.pages:
                        page_text = page.extract_text()
                        if page_text:
                            text += page_text + "\n"
                
                if text.strip() and len(text.strip()) > 100:
                    logger.info("‚úÖ Texte extrait avec pdfplumber")
                    return text
                    
            except ImportError:
                logger.warning("pdfplumber non disponible")
            except Exception as e:
                logger.warning(f"Erreur pdfplumber: {e}")
            
            # Essayer avec pymupdf
            try:
                import fitz  # PyMuPDF
                
                pdf_document = fitz.open(stream=pdf_bytes, filetype="pdf")
                text = ""
                
                for page_num in range(pdf_document.page_count):
                    page = pdf_document[page_num]
                    text += page.get_text() + "\n"
                
                pdf_document.close()
                
                if text.strip() and len(text.strip()) > 100:
                    logger.info("‚úÖ Texte extrait avec PyMuPDF")
                    return text
                    
            except ImportError:
                logger.warning("PyMuPDF non disponible")
            except Exception as e:
                logger.warning(f"Erreur PyMuPDF: {e}")
            
            # Si peu ou pas de texte, essayer OCR (PDF scann√©)
            text = self._extract_text_with_ocr(pdf_bytes)
            if text and len(text.strip()) > 100:
                logger.info("‚úÖ Texte extrait avec OCR")
                return text
            
            logger.warning("‚ö†Ô∏è Aucune biblioth√®que PDF disponible ou texte insuffisant")
            return ""
            
        except Exception as e:
            logger.error(f"Erreur extraction texte depuis bytes: {e}")
            return ""
    
    def _extract_text_with_ocr(self, pdf_bytes: bytes) -> str:
        """
        Extrait le texte d'un PDF scann√© avec OCR
        
        Args:
            pdf_bytes: Contenu PDF en bytes
            
        Returns:
            Texte extrait via OCR
        """
        try:
            # Essayer avec pytesseract
            try:
                import pytesseract
                from pdf2image import convert_from_bytes
                
                # Convertir le PDF en images
                images = convert_from_bytes(pdf_bytes, dpi=300)
                
                ocr_text = ""
                for img in images:
                    # Extraire le texte avec OCR (fran√ßais)
                    page_text = pytesseract.image_to_string(img, lang='fra')
                    if page_text:
                        ocr_text += page_text + "\n"
                
                if ocr_text.strip():
                    logger.info(f"‚úÖ OCR pytesseract: {len(ocr_text)} caract√®res extraits")
                    return ocr_text
                    
            except ImportError:
                logger.debug("pytesseract non disponible")
            except Exception as e:
                logger.debug(f"Erreur OCR pytesseract: {e}")
            
            # Essayer avec easyocr (alternative)
            try:
                import easyocr
                
                reader = easyocr.Reader(['fr', 'en'])
                images = convert_from_bytes(pdf_bytes, dpi=300)
                
                ocr_text = ""
                for img in images:
                    results = reader.readtext(img)
                    page_text = "\n".join([result[1] for result in results])
                    if page_text:
                        ocr_text += page_text + "\n"
                
                if ocr_text.strip():
                    logger.info(f"‚úÖ OCR easyocr: {len(ocr_text)} caract√®res extraits")
                    return ocr_text
                    
            except ImportError:
                logger.debug("easyocr non disponible")
            except Exception as e:
                logger.debug(f"Erreur OCR easyocr: {e}")
            
            return ""
            
        except Exception as e:
            logger.debug(f"Erreur OCR: {e}")
            return ""
    
    def _extract_tables_from_pdf(self, pdf_bytes: bytes) -> List[Dict[str, Any]]:
        """
        Extrait les tableaux structur√©s du PDF
        
        Args:
            pdf_bytes: Contenu PDF en bytes
            
        Returns:
            Liste des tableaux extraits avec leurs donn√©es structur√©es
        """
        tables_data = []
        
        try:
            import pdfplumber
            
            with pdfplumber.open(BytesIO(pdf_bytes)) as pdf:
                for page_num, page in enumerate(pdf.pages):
                    tables = page.extract_tables()
                    
                    for table_index, table in enumerate(tables):
                        if table and len(table) > 0:
                            # Structurer le tableau
                            structured_table = self._structure_table(table)
                            
                            if structured_table:
                                tables_data.append({
                                    'page': page_num + 1,
                                    'table_index': table_index,
                                    'rows': len(table),
                                    'columns': len(table[0]) if table else 0,
                                    'data': structured_table
                                })
                                logger.debug(f"üìä Tableau extrait page {page_num + 1}, table {table_index}: {len(structured_table)} entr√©es")
            
            if tables_data:
                logger.info(f"‚úÖ {len(tables_data)} tableaux structur√©s extraits du PDF")
            
        except ImportError:
            logger.warning("pdfplumber non disponible pour extraction de tableaux")
        except Exception as e:
            logger.warning(f"Erreur extraction tableaux: {e}")
        
        return tables_data
    
    def _structure_table(self, table: List[List]) -> List[Dict[str, Any]]:
        """
        Structure un tableau extrait en dictionnaire
        
        Args:
            table: Tableau brut extrait (liste de listes)
            
        Returns:
            Liste de dictionnaires structur√©s
        """
        if not table or len(table) < 2:
            return []
        
        structured = []
        headers = [str(cell).strip() if cell else f"Col_{i}" 
                  for i, cell in enumerate(table[0])]
        
        for row in table[1:]:
            if not row or not any(cell for cell in row):
                continue
            
            row_dict = {}
            for i, cell in enumerate(row):
                header = headers[i] if i < len(headers) else f"Col_{i}"
                row_dict[header] = str(cell).strip() if cell else ""
            
            # Filtrer les lignes vides
            if any(row_dict.values()):
                structured.append(row_dict)
        
        return structured
    
    def _create_entries_for_lots(self, lots: List[LotInfo], text_content: str) -> List[Dict[str, Any]]:
        """
        Cr√©e des entr√©es pour chaque lot d√©tect√©
        
        Args:
            lots: Liste des lots d√©tect√©s
            text_content: Contenu texte du PDF
            
        Returns:
            Liste des entr√©es cr√©√©es
        """
        entries = []
        
        try:
            logger.info(f"üìù Cr√©ation des entr√©es pour {len(lots)} lots...")
            
            # Extraire les informations g√©n√©rales du PDF
            general_info = self._extract_general_info(text_content)
            
            # Extraire les crit√®res par lot
            criteres_par_lot = self._extract_criteres_by_lot(text_content, lots)
            
            # Log des informations g√©n√©rales AVANT de cr√©er les entr√©es
            logger.info(f"üìã General info avant cr√©ation entr√©es: {list(general_info.keys())}")
            for date_field in ['date_limite', 'date_attribution', 'duree_marche', 'reconduction', 'fin_sans_reconduction', 'fin_avec_reconduction']:
                if date_field in general_info:
                    logger.info(f"‚úÖ {date_field} dans general_info: '{general_info[date_field]}'")
            
            for lot in lots:
                # Cr√©er une entr√©e pour ce lot
                lot_entry = {
                    'valeurs_extraites': general_info.copy(),
                    'valeurs_generees': {},
                    'statistiques': {}
                }
                
                # Ajouter les informations sp√©cifiques au lot
                lot_entry['valeurs_extraites']['nbr_lots'] = len(lots)
                lot_entry['valeurs_extraites']['lot_numero'] = lot.numero
                lot_entry['valeurs_extraites']['intitule_lot'] = lot.intitule
                lot_entry['valeurs_extraites']['montant_global_estime'] = lot.montant_estime
                lot_entry['valeurs_extraites']['montant_global_maxi'] = lot.montant_maximum
                lot_entry['valeurs_extraites']['quantite_minimum'] = lot.quantite_minimum
                lot_entry['valeurs_extraites']['quantites_estimees'] = lot.quantites_estimees
                lot_entry['valeurs_extraites']['quantite_maximum'] = lot.quantite_maximum
                
                # Ajouter les crit√®res sp√©cifiques au lot si disponibles
                if lot.numero in criteres_par_lot:
                    lot_entry['valeurs_extraites']['criteres_economique'] = criteres_par_lot[lot.numero].get('criteres_economique', '')
                    lot_entry['valeurs_extraites']['criteres_techniques'] = criteres_par_lot[lot.numero].get('criteres_techniques', '')
                    lot_entry['valeurs_extraites']['autres_criteres'] = criteres_par_lot[lot.numero].get('autres_criteres', '')
                else:
                    # Utiliser les crit√®res g√©n√©raux
                    lot_entry['valeurs_extraites']['criteres_economique'] = lot.criteres_economique
                    lot_entry['valeurs_extraites']['criteres_techniques'] = lot.criteres_techniques
                    lot_entry['valeurs_extraites']['autres_criteres'] = lot.autres_criteres
                
                lot_entry['valeurs_extraites']['rse'] = lot.rse
                lot_entry['valeurs_extraites']['contribution_fournisseur'] = lot.contribution_fournisseur
                
                # G√©n√©rer les valeurs manquantes
                lot_entry['valeurs_extraites'] = self.generate_missing_values(lot_entry['valeurs_extraites'])
                
                # Calculer les statistiques
                lot_entry['statistiques'] = self.calculate_extraction_stats(lot_entry['valeurs_extraites'])
                
                # Ajouter des m√©tadonn√©es
                lot_entry['lot_id'] = f"LOT_{lot.numero}"
                lot_entry['extraction_source'] = lot.source
                lot_entry['extraction_timestamp'] = self._get_current_timestamp()
                lot_entry['text_source'] = text_content  # Pour l'enrichissement avec extraction_improver
                
                entries.append(lot_entry)
                logger.info(f"üì¶ Entr√©e PDF cr√©√©e pour le lot {lot.numero}: {lot.intitule[:50]}...")
            
            logger.info(f"‚úÖ Cr√©ation des entr√©es PDF termin√©e: {len(entries)} entr√©es cr√©√©es")
            
        except Exception as e:
            logger.error(f"Erreur lors de la cr√©ation des entr√©es PDF: {e}")
        
        return entries
    
    def _extract_single_entry(self, text_content: str) -> List[Dict[str, Any]]:
        """
        Extrait une seule entr√©e (pas de lots d√©tect√©s)
        
        Args:
            text_content: Contenu texte du PDF
            
        Returns:
            Liste avec une seule entr√©e
        """
        try:
            logger.info("üìÑ Extraction d'entr√©e unique PDF...")
            
            # Extraire les informations g√©n√©rales
            general_info = self._extract_general_info(text_content)
            
            # Cr√©er l'entr√©e
            entry = {
                'valeurs_extraites': general_info,
                'valeurs_generees': {},
                'statistiques': {}
            }
            
            # Ajouter des valeurs par d√©faut
            entry['valeurs_extraites']['nbr_lots'] = 1
            entry['valeurs_extraites']['lot_numero'] = 1
            entry['valeurs_extraites']['intitule_lot'] = entry['valeurs_extraites'].get('intitule_procedure', 'Lot unique')
            
            # G√©n√©rer les valeurs manquantes
            entry['valeurs_extraites'] = self.generate_missing_values(entry['valeurs_extraites'])
            
            # Calculer les statistiques
            entry['statistiques'] = self.calculate_extraction_stats(entry['valeurs_extraites'])
            
            # Ajouter des m√©tadonn√©es
            entry['extraction_source'] = 'pdf_single_entry'
            entry['extraction_timestamp'] = self._get_current_timestamp()
            entry['text_source'] = text_content  # Pour l'enrichissement avec extraction_improver
            
            logger.info("‚úÖ Entr√©e PDF unique cr√©√©e")
            return [entry]
            
        except Exception as e:
            logger.error(f"Erreur extraction entr√©e unique PDF: {e}")
            return [{'erreur': f"Erreur extraction entr√©e unique PDF: {e}"}]
    
    def _extract_general_info(self, text_content: str) -> Dict[str, Any]:
        """
        Extrait les informations g√©n√©rales du PDF
        
        Args:
            text_content: Contenu texte du PDF
            
        Returns:
            Dictionnaire des informations g√©n√©rales
        """
        general_info = {}
        try:
            # Extraire d'abord le titre du document pour l'intitul√© de proc√©dure (priorit√©)
            document_title = self._extract_document_title(text_content)
            if document_title and len(document_title.strip()) >= 10:
                general_info['intitule_procedure'] = document_title.strip()
                logger.info(f"üìÑ Titre du document d√©tect√© comme intitul√©: {document_title[:60]}...")
            
            fields_to_extract = [
                'reference_procedure', 'intitule_procedure', 'groupement',
                'type_procedure', 'mono_multi', 'date_limite', 'date_attribution',
                'duree_marche', 'montant_global_estime', 'montant_global_maxi',
                'quantite_minimum', 'quantites_estimees', 'quantite_maximum',
                'criteres_economique', 'criteres_techniques', 'autres_criteres',
                'rse', 'contribution_fournisseur', 'infos_complementaires',
                'execution_marche', 'reconduction', 'fin_sans_reconduction', 'fin_avec_reconduction',
                'achat', 'credit_bail', 'credit_bail_duree', 'location', 'location_duree', 'mad',
                'attributaire', 'produit_retenu', 'segment', 'famille',
                'remarques', 'notes_acheteur_procedure', 'notes_acheteur_fournisseur', 
                'notes_acheteur_positionnement'
            ]

            # Pr√©parer les groupes de patterns
            pattern_groups = {}
            for field in fields_to_extract:
                patterns = self.pattern_manager.get_field_patterns(field)
                if patterns:
                    pattern_groups[field] = patterns
                # Log pour les champs de dates importants
                if field in ['date_limite', 'date_attribution', 'duree_marche', 'reconduction']:
                    logger.debug(f"üîç Patterns pour {field}: {len(patterns)} patterns charg√©s")

            # Extraire d'abord par sections pour r√©duire les faux positifs
            sections = self._split_into_sections(text_content)
            
            # Log des sections trouv√©es pour les dates
            for section_field in ['date_limite', 'date_attribution', 'duree_marche', 'reconduction', 'fin_sans_reconduction', 'fin_avec_reconduction']:
                if section_field in sections:
                    logger.info(f"üìã Section trouv√©e pour {section_field}: {sections[section_field][:100]}...")
                else:
                    logger.debug(f"‚ö†Ô∏è Pas de section trouv√©e pour {section_field}, recherche dans tout le texte")

            # Extraction combin√©e: par section (si disponible), sinon sur tout le texte
            if pattern_groups:
                parallel_results = {}
                for field, patterns in pattern_groups.items():
                    # Ne pas chercher intitule_procedure si d√©j√† extrait depuis le titre du document
                    if field == 'intitule_procedure' and 'intitule_procedure' in general_info:
                        continue
                    
                    section_text = sections.get(field) or text_content
                    # Ex√©cuter extraction cibl√©e champ par champ pour passer la section
                    values = self.extract_with_patterns(section_text, patterns, field)
                    parallel_results[field] = values
                    
                    # Log pour debug - TOUJOURS logger m√™me si vide
                    if field in ['date_limite', 'date_attribution', 'duree_marche', 'reconduction', 'fin_sans_reconduction', 'fin_avec_reconduction']:
                        if values:
                            logger.info(f"‚úÖ {field}: {values[:3]}")  # Afficher les 3 premi√®res valeurs
                        else:
                            logger.warning(f"‚ùå {field}: Aucune valeur trouv√©e (section: {bool(sections.get(field))}, patterns: {len(patterns)})")
                for field, values in parallel_results.items():
                    if values:
                        cleaned_value = self.clean_extracted_value(values[0], self._get_field_type(field))
                        # Normaliser les valeurs sp√©ciales
                        if field == 'type_procedure':
                            cleaned_value = self._normalize_type_procedure(cleaned_value)
                        elif field == 'mono_multi':
                            cleaned_value = self._normalize_mono_multi(cleaned_value, general_info.get('nbr_lots'))
                        
                        if cleaned_value:
                            # Ne pas √©craser le titre du document si d√©j√† pr√©sent
                            if field == 'intitule_procedure' and 'intitule_procedure' in general_info:
                                # Comparer les longueurs et garder le plus long (souvent plus complet)
                                if len(cleaned_value) > len(general_info['intitule_procedure']):
                                    general_info[field] = cleaned_value
                            else:
                                general_info[field] = cleaned_value

            logger.info(f"üìä Informations g√©n√©rales extraites: {len(general_info)} champs")
            
            # Log explicite des dates extraites (avec liste compl√®te des champs)
            date_fields = ['date_limite', 'date_attribution', 'duree_marche', 'reconduction', 'fin_sans_reconduction', 'fin_avec_reconduction']
            logger.info(f"üìã Champs g√©n√©raux disponibles: {list(general_info.keys())}")
            for date_field in date_fields:
                if date_field in general_info:
                    logger.info(f"‚úÖ {date_field} EXTRAIT: '{general_info[date_field]}'")
                else:
                    logger.warning(f"‚ùå {date_field} MANQUANT dans general_info")
        except Exception as e:
            logger.error(f"Erreur extraction informations g√©n√©rales PDF: {e}")
            import traceback
            logger.error(traceback.format_exc())
        return general_info

    def _split_into_sections(self, text: str) -> Dict[str, str]:
        """
        D√©coupe grossi√®rement le texte en sections cl√©s et mappe vers les champs.
        """
        try:
            lowered = text.lower()
            sections: Dict[str, str] = {}

            def grab(after: str, until: List[str]) -> str:
                start = lowered.find(after)
                if start == -1:
                    return ""
                start_end = start + len(after)
                next_positions = [lowered.find(u, start_end) for u in until]
                next_positions = [p for p in next_positions if p != -1]
                end = min(next_positions) if next_positions else len(text)
                return text[start_end:end]

            # D√©finir des s√©parateurs g√©n√©riques
            stops = ["\n\n", "\narticle", "\nsection", "\nchapitre", "\nannexe", "\nlot "]

            # Map sections -> champs
            # IMPORTANT: Ajouter les sections pour les dates importantes
            sections_raw = {
                'date_limite': grab('date limite', stops) or grab('√©ch√©ance', stops) or grab('cl√¥ture', stops) or grab('cloture', stops) or grab('remise', stops) or grab('d√©p√¥t', stops) or grab('depot', stops),
                'date_attribution': grab('date attribution', stops) or grab('attribution', stops) or grab('attribu√©', stops) or grab('attribue', stops),
                'duree_marche': grab('dur√©e', stops) or grab('duree', stops),
                'execution_marche': grab("ex√©cution du march√©", stops) or grab('execution du marche', stops),
                'reconduction': grab('reconduction', stops) or grab('renouvellement', stops),
                'fin_sans_reconduction': grab('fin sans reconduction', stops),
                'fin_avec_reconduction': grab('fin avec reconduction', stops),
                'rse': grab('rse', stops) or grab('responsabilit√© soci√©tale', stops) or grab('developpement durable', stops),
                'contribution_fournisseur': grab('contribution fournisseur', stops) or grab('participation fournisseur', stops),
                'infos_complementaires': grab('informations compl√©mentaires', stops) or grab('renseignements compl√©mentaires', stops) or grab('infos compl√©mentaires', stops),
                'achat': grab('achat', stops) or grab('acquisition', stops),
                'credit_bail': grab('cr√©dit-bail', stops) or grab('credit-bail', stops),
                'location': grab('location', stops),
                'mad': grab('mise √† disposition', stops) or grab('mad', stops),
                'attributaire': grab('attributaire', stops) or grab('titulaire', stops) or grab('adjudicataire', stops),
                'produit_retenu': grab('produit retenu', stops) or grab('solution retenue', stops),
                'segment': grab('segment', stops),
                'famille': grab('famille', stops)
            }

            # R√©pliquer pour toutes les cl√©s attendues
            for k, v in sections_raw.items():
                if v:
                    sections[k] = v
            return sections
        except Exception:
            return {}
    
    def _extract_criteres_by_lot(self, text_content: str, lots: List[LotInfo]) -> Dict[int, Dict[str, str]]:
        """
        Extrait les crit√®res d'attribution par lot
        
        Args:
            text_content: Contenu texte du PDF
            lots: Liste des lots d√©tect√©s
            
        Returns:
            Dictionnaire {numero_lot: {criteres}}
        """
        criteres_par_lot = {}
        
        try:
            logger.info("üîç Extraction des crit√®res par lot...")
            
            # Pour chaque lot, chercher les crit√®res dans son contexte
            for lot in lots:
                lot_numero = lot.numero
                criteres_lot = {
                    'criteres_economique': '',
                    'criteres_techniques': '',
                    'autres_criteres': ''
                }
                
                # Chercher les crit√®res dans le contexte du lot
                lot_context = self._extract_lot_context(text_content, lot_numero)
                if lot_context:
                    # Extraire les crit√®res depuis le contexte
                    for critere_type in ['criteres_economique', 'criteres_techniques', 'autres_criteres']:
                        patterns = self.pattern_manager.get_field_patterns(critere_type)
                        if patterns:
                            values = self.extract_with_patterns(lot_context, patterns, critere_type)
                            if values:
                                criteres_lot[critere_type] = values[0]
                
                criteres_par_lot[lot_numero] = criteres_lot
                logger.info(f"üìä Crit√®res lot {lot_numero}: √âco={criteres_lot['criteres_economique']}, Tech={criteres_lot['criteres_techniques']}")
            
        except Exception as e:
            logger.error(f"Erreur extraction crit√®res par lot: {e}")
        
        return criteres_par_lot
    
    def _extract_lot_context(self, text: str, lot_numero: int) -> str:
        """
        Extrait le contexte autour d'un lot sp√©cifique
        
        Args:
            text: Texte complet
            lot_numero: Num√©ro du lot
            
        Returns:
            Contexte du lot
        """
        try:
            # Chercher le lot dans le texte
            lot_pattern = rf'lot\s*n¬∞?\s*{lot_numero}[^\n]*\n(.*?)(?=\nlot\s*n¬∞?\s*\d+|\n\n|$)'
            match = re.search(lot_pattern, text, re.IGNORECASE | re.DOTALL)
            
            if match:
                return match.group(1)
            
            # Pattern alternatif plus large
            lot_pattern_alt = rf'lot\s*{lot_numero}[^\n]*\n(.*?)(?=\nlot\s*\d+|\n\n|$)'
            match_alt = re.search(lot_pattern_alt, text, re.IGNORECASE | re.DOTALL)
            
            if match_alt:
                return match_alt.group(1)
            
            return ""
            
        except Exception as e:
            logger.error(f"Erreur extraction contexte lot {lot_numero}: {e}")
            return ""
    
    def _get_field_type(self, field_name: str) -> str:
        """D√©termine le type d'un champ pour le nettoyage"""
        if 'montant' in field_name.lower():
            return 'montant'
        elif 'date' in field_name.lower():
            return 'date'
        elif 'duree' in field_name.lower() or 'dur√©e' in field_name.lower():
            return 'duree'
        elif 'reconduction' in field_name.lower():
            return 'reconduction'
        elif 'reference' in field_name.lower():
            return 'reference'
        else:
            return 'text'
    
    def _normalize_type_procedure(self, value: str) -> str:
        """
        Normalise la valeur du type de proc√©dure
        
        Args:
            value: Valeur brute extraite
            
        Returns:
            Valeur normalis√©e ou None
        """
        if not value or not isinstance(value, str):
            return None
        
        value_lower = value.lower().strip()
        
        # Mapping des valeurs vers les types normalis√©s
        if 'ouvert' in value_lower and ('appel' in value_lower or 'offre' in value_lower or 'ao' in value_lower):
            return 'Appel d\'offres ouvert'
        elif 'restreint' in value_lower and ('appel' in value_lower or 'offre' in value_lower or 'ao' in value_lower):
            return 'Appel d\'offres restreint'
        elif 'consultation' in value_lower:
            return 'Consultation'
        elif 'achat direct' in value_lower or 'commande' in value_lower:
            return 'Achat direct'
        elif 'convention' in value_lower or 'accord cadre' in value_lower:
            return 'Convention'
        elif 'march√© de services' in value_lower:
            return 'Consultation'
        elif len(value.strip()) > 5:  # Garder la valeur originale si elle est assez longue et non reconnue
            return value.strip()
        
        return None
    
    def _normalize_mono_multi(self, value: str, nbr_lots: int = None) -> str:
        """
        Normalise la valeur mono_multi
        
        Args:
            value: Valeur brute extraite
            nbr_lots: Nombre de lots d√©tect√©s (pour inf√©rence si n√©cessaire)
            
        Returns:
            Valeur normalis√©e ou None
        """
        if not value or not isinstance(value, str):
            # Inf√©rer depuis le nombre de lots si disponible
            if nbr_lots is not None:
                return 'Multi-attributif' if nbr_lots > 1 else 'Mono-attributif'
            return None
        
        value_lower = value.lower().strip()
        
        # Mapping des valeurs
        if any(word in value_lower for word in ['multi', 'multiple', 'alloti', 'lotissement', 'lotti']):
            return 'Multi-attributif'
        elif any(word in value_lower for word in ['mono', 'unique', 'unitaire']):
            return 'Mono-attributif'
        elif nbr_lots is not None:
            # Inf√©rer depuis le nombre de lots
            return 'Multi-attributif' if nbr_lots > 1 else 'Mono-attributif'
        
        return None
    
    def _extract_document_title(self, text_content: str) -> Optional[str]:
        """
        Extrait le titre du document (g√©n√©ralement un paragraphe en majuscules sur plusieurs lignes)
        
        Le titre du document est souvent l'intitul√© de la proc√©dure.
        Peut √™tre sur plusieurs lignes, souvent dans le 2√®me paragraphe en majuscules.
        
        Args:
            text_content: Contenu texte du PDF
            
        Returns:
            Titre du document ou None
        """
        try:
            lines = text_content.split('\n')
            
            # Prendre les 30 premi√®res lignes (pour capturer le 2√®me paragraphe aussi)
            first_lines = lines[:30]
            
            # Mots d'en-t√™te √† exclure (ne sont pas le titre)
            header_keywords = [
                'r√®glement', 'reglement', 'r√®glement de consultation', 'rc',
                'appel d\'offres', 'appel d\'offre', 'ao', 'marche', 'march√©',
                'procedure', 'proc√©dure', 'consultation', 'avis',
                'reference', 'r√©f√©rence', 'ref', 'numero', 'num√©ro', 'n¬∞',
                'date', 'groupement', 'organisme', 'acheteur',
                'lot', 'lots', 'lotissement', 'allotissement',
                'article', 'chapitre', 'section', 'annexe', 'centrale',
                'pouvoir adjudicateur', 'accord-cadre', 'accords-cadres'
            ]
            
            candidates = []
            multi_line_candidates = []  # Pour les titres sur plusieurs lignes
            
            # 1. Chercher des blocs de lignes en majuscules cons√©cutives (titres multi-lignes)
            i = 0
            while i < len(first_lines) - 1:
                current_block = []
                start_idx = i
                
                # Chercher un bloc de lignes en majuscules cons√©cutives
                while i < len(first_lines):
                    line = first_lines[i].strip()
                    line_lower = line.lower()
                    
                    # Ignorer les lignes vides
                    if not line:
                        i += 1
                        continue
                    
                    # Arr√™ter si on rencontre un en-t√™te √©vident
                    if any(keyword in line_lower for keyword in header_keywords):
                        if current_block:
                            break
                        i += 1
                        continue
                    
                    # Ignorer les dates et r√©f√©rences
                    if re.match(r'^\d{1,2}[/-]\d{1,2}[/-]\d{2,4}', line):
                        if current_block:
                            break
                        i += 1
                        continue
                    if re.match(r'^\d{4}-[A-Z]\d{3}', line):
                        if current_block:
                            break
                        i += 1
                        continue
                    
                    # Si ligne en majuscules significative (‚â• 20 chars)
                    # V√©rifier si c'est principalement en majuscules (‚â• 80% des lettres)
                    letters = [c for c in line if c.isalpha()]
                    upper_letters = [c for c in line if c.isupper()]
                    is_mostly_upper = len(letters) > 0 and (len(upper_letters) / len(letters)) >= 0.8
                    is_long_enough = len(line) >= 20
                    
                    is_upper = is_mostly_upper and is_long_enough
                    is_in_block = len(current_block) > 0
                    
                    # Accepter si majuscules OU si d√©j√† dans un bloc (pour continuer le titre multi-lignes)
                    if is_upper or (is_in_block and len(line) >= 15 and is_mostly_upper):
                        current_block.append(line)
                        i += 1
                    else:
                        # Si on a d√©j√† un bloc, l'arr√™ter
                        if current_block:
                            break
                        i += 1
                
                # Si on a un bloc de plusieurs lignes en majuscules, c'est probablement le titre
                if len(current_block) >= 1:
                    # Joindre les lignes du bloc
                    block_text = ' '.join(current_block)
                    
                    # Filtrer si trop court ou trop long
                    if 30 <= len(block_text) <= 500:
                        # Score bas√© sur plusieurs crit√®res
                        score = 0
                        
                        # +15 si toutes les lignes sont principalement en majuscules (‚â• 80%)
                        def is_mostly_uppercase(s):
                            letters = [c for c in s if c.isalpha()]
                            if not letters:
                                return False
                            upper_letters = [c for c in s if c.isupper()]
                            return (len(upper_letters) / len(letters)) >= 0.8
                        
                        if all(is_mostly_uppercase(l) for l in current_block if l):
                            score += 15
                        
                        # +10 si c'est un bloc de plusieurs lignes (2+)
                        if len(current_block) >= 2:
                            score += 10
                        
                        # +8 si dans les 15 premi√®res lignes (2√®me paragraphe souvent)
                        if start_idx < 15:
                            score += 8
                        
                        # +5 si contient des mots significatifs
                        block_lower = block_text.lower()
                        significant_words = [
                            'prestation', 'formation', 'achat', 'fourniture', 'fournitures',
                            'equipement', 'equipements', 'service', 'services', 'maintenance',
                            'logiciel', 'logiciels', 'materiel', 'consommable', 'mobilier',
                            'installation', 'mise en service', 'ventilation', 'transport',
                            'monitorage', 'localisation'
                        ]
                        if any(word in block_lower for word in significant_words):
                            score += 5
                        
                        # +3 si longueur optimale (50-300 caract√®res)
                        if 50 <= len(block_text) <= 300:
                            score += 3
                        
                        # -5 si contient trop de mots techniques
                        technical_words = ['page', 'total', 'code', 'article', 'dispositions']
                        tech_count = sum(1 for word in technical_words if word in block_lower)
                        score -= tech_count * 2
                        
                        if score > 0:
                            multi_line_candidates.append((score, block_text, start_idx, len(current_block)))
            
            # 2. Chercher aussi des lignes individuelles en majuscules (fallback)
            for i, line in enumerate(first_lines):
                line = line.strip()
                
                # Ignorer les lignes trop courtes ou trop longues
                if len(line) < 30 or len(line) > 500:
                    continue
                
                # Ignorer les lignes vides
                if not line:
                    continue
                
                # Ignorer les lignes qui sont clairement des en-t√™tes
                line_lower = line.lower()
                if any(keyword in line_lower for keyword in header_keywords):
                    continue
                
                # Ignorer les lignes qui sont des dates ou r√©f√©rences
                if re.match(r'^\d{1,2}[/-]\d{1,2}[/-]\d{2,4}', line):
                    continue
                if re.match(r'^\d{4}-[A-Z]\d{3}', line):
                    continue
                
                # Chercher des lignes principalement en majuscules significatives (titres longs)
                # V√©rifier si ‚â• 80% des lettres sont en majuscules
                letters = [c for c in line if c.isalpha()]
                if letters:
                    upper_ratio = len([c for c in line if c.isupper() and c.isalpha()]) / len(letters)
                    is_mostly_upper_line = upper_ratio >= 0.8 and len(line) >= 30
                else:
                    is_mostly_upper_line = False
                
                if is_mostly_upper_line:
                    score = 0
                    
                    # +10 si la ligne est en majuscules et longue
                    if len(line) >= 50:
                        score += 10
                    else:
                        score += 5
                    
                    # +5 si elle est dans les 15 premi√®res lignes (2√®me paragraphe)
                    if i < 15:
                        score += 5
                    
                    # +5 si elle contient des mots significatifs
                    significant_words = [
                        'prestation', 'formation', 'achat', 'fourniture', 'fournitures',
                        'equipement', 'equipements', 'service', 'services', 'maintenance',
                        'logiciel', 'logiciels', 'installation', 'ventilation'
                    ]
                    if any(word in line_lower for word in significant_words):
                        score += 5
                    
                    # +3 si longueur raisonnable (50-300 caract√®res)
                    if 50 <= len(line) <= 300:
                        score += 3
                    
                    if score > 0:
                        candidates.append((score, line, i))
            
            # Trier les candidats multi-lignes par score (priorit√©)
            multi_line_candidates.sort(key=lambda x: (-x[0], x[2]))
            
            # Trier les candidats simples
            candidates.sort(key=lambda x: (-x[0], x[2]))
            
            # Pr√©f√©rer les blocs multi-lignes si score √©lev√©
            if multi_line_candidates and multi_line_candidates[0][0] >= 15:
                best_candidate = multi_line_candidates[0][1]
                logger.debug(f"üìÑ Titre multi-lignes d√©tect√© ({multi_line_candidates[0][3]} lignes)")
            elif candidates:
                best_candidate = candidates[0][1]
                logger.debug(f"üìÑ Titre ligne unique d√©tect√©")
            else:
                return None
            
            # Nettoyer le titre
            cleaned_title = best_candidate.strip()
            # Supprimer les caract√®res de formatage excessifs
            cleaned_title = re.sub(r'\s+', ' ', cleaned_title)
            # Limiter la longueur si vraiment trop long (garder jusqu'√† 400 caract√®res pour phrases longues)
            if len(cleaned_title) > 400:
                cleaned_title = cleaned_title[:400].rsplit(' ', 1)[0] + '...'
            
            logger.info(f"üìÑ Titre du document extrait: {cleaned_title[:80]}...")
            return cleaned_title
            
        except Exception as e:
            logger.debug(f"Erreur extraction titre document: {e}")
            return None
    
    def _get_current_timestamp(self) -> str:
        """Retourne le timestamp actuel"""
        from datetime import datetime
        return datetime.now().isoformat()

"""
üöÄ AOExtractor V2 - Architecture Modulaire
==========================================

Version refactoris√©e du AOExtractor utilisant l'architecture modulaire.
Remplace l'ancien ao_extractor.py avec une approche plus maintenable.
"""

import pandas as pd
import logging
import time
import traceback
import hashlib
from typing import Dict, Any, List, Optional, Union
from datetime import datetime
import os

# Import des modules modulaires
from extractors import (
    PatternManager, ValidationEngine, PDFExtractor, 
    ExcelExtractor, TextExtractor, LotDetector
)
from extractors.file_type_detector import FileTypeDetector
from extractors.intelligent_post_processor import IntelligentPostProcessor
from extractors.database_context_learner import DatabaseContextLearner
from extractors.extraction_cache import ExtractionCache

logger = logging.getLogger(__name__)

class AOExtractorV2:
    """
    Extracteur d'Appels d'Offres V2 - Architecture Modulaire
    
    Version refactoris√©e utilisant une architecture modulaire pour une meilleure
    maintenabilit√©, performance et extensibilit√©.
    """
    
    def __init__(self, reference_data: pd.DataFrame = None, database_manager=None):
        """
        Initialise l'extracteur V2
        
        Args:
            reference_data: DataFrame de r√©f√©rence pour l'apprentissage (optionnel)
            database_manager: Instance de DatabaseManager pour apprendre depuis la BDD (optionnel)
        """
        self.reference_data = reference_data
        self.database_manager = database_manager
        
        # Initialiser les composants modulaires
        self.pattern_manager = PatternManager()
        self.validation_engine = ValidationEngine()
        self.lot_detector = LotDetector()
        
        # Initialiser l'apprenant contextuel depuis la BDD
        self.database_learner = DatabaseContextLearner(database_manager)
        if database_manager:
            # Apprendre depuis la BDD de mani√®re asynchrone pour ne pas bloquer
            try:
                self.database_learner.learn_from_database(limit=500)
                logger.info("‚úÖ Apprentissage depuis la base de donn√©es termin√©")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Erreur apprentissage BDD: {e}")
        
        # Initialiser les extracteurs sp√©cialis√©s
        self.pdf_extractor = PDFExtractor(self.pattern_manager, self.validation_engine)
        self.excel_extractor = ExcelExtractor(self.pattern_manager, self.validation_engine)
        self.text_extractor = TextExtractor(self.pattern_manager, self.validation_engine)
        
        # Passer le database_learner aux extracteurs pour la g√©n√©ration intelligente
        if self.database_learner:
            self.pdf_extractor.database_learner = self.database_learner
            self.excel_extractor.database_learner = self.database_learner
            self.text_extractor.database_learner = self.database_learner
        
        # Initialiser le d√©tecteur de type de fichier unifi√©
        self.file_type_detector = FileTypeDetector
        
        # Initialiser le post-processeur intelligent
        self.intelligent_processor = IntelligentPostProcessor(enable_improver=True)
        
        # Initialiser le cache intelligent pour les extractions
        self.extraction_cache = ExtractionCache(max_size=1000)
        
        # M√©triques de performance am√©lior√©es
        self.performance_metrics = {
            'total_extractions': 0,
            'successful_extractions': 0,
            'extraction_errors': 0,
            'average_extraction_time': 0.0,
            'extraction_by_type': {
                'pdf': 0,
                'excel': 0,
                'text': 0,
                'other': 0
            },
            'errors_by_type': {},
            'extraction_time_by_type': {
                'pdf': [],
                'excel': [],
                'text': [],
                'other': []
            },
            'field_extraction_stats': {},
            'validation_failure_reasons': {}
        }
        
        # Apprentissage depuis les donn√©es de r√©f√©rence
        if self.reference_data is not None and not self.reference_data.empty:
            self._learn_from_reference_data()
        # Note: L'apprentissage depuis la BDD est d√©j√† fait au-dessus si database_manager est fourni
        
        logger.info("üöÄ AOExtractor V2 initialis√© avec architecture modulaire")
    
    def extract_from_file(self, uploaded_file, file_analysis: Dict[str, Any], target_columns: List[str] = None) -> List[Dict[str, Any]]:
        """
        Extrait les informations d'un appel d'offres depuis un fichier upload√©
        
        Args:
            uploaded_file: Fichier upload√© par l'utilisateur
            file_analysis: Analyse pr√©liminaire du fichier
            target_columns: Liste des colonnes cibles de la base de donn√©es
            
        Returns:
            Liste des donn√©es extraites
        """
        start_time = time.time()
        
        try:
            self.performance_metrics['total_extractions'] += 1
            logger.info(f"üìÅ Extraction depuis le fichier: {uploaded_file.name}")
            
            # Initialiser cache_key pour utilisation ult√©rieure
            cache_key = None
            
            # V√©rifier le cache avant d'extraire
            try:
                # Lire le contenu pour g√©n√©rer la cl√© de cache
                uploaded_file.seek(0)
                file_content = uploaded_file.read()
                uploaded_file.seek(0)
                
                cache_key = self.extraction_cache.get_cache_key(file_content, uploaded_file.name)
                cached_result = self.extraction_cache.get(cache_key)
                
                if cached_result:
                    logger.info(f"‚úÖ R√©sultat r√©cup√©r√© depuis le cache pour {uploaded_file.name}")
                    self.performance_metrics['successful_extractions'] += 1
                    return cached_result
            except Exception as e:
                logger.debug(f"Erreur v√©rification cache: {e}")
            
            # D√©terminer le type de fichier avec le d√©tecteur unifi√©
            file_type = self.file_type_detector.detect(
                file_name=uploaded_file.name,
                file_analysis=file_analysis
            )
            logger.info(f"üìã Type de fichier d√©tect√©: {file_type}")
            
            extractor = self._get_extractor_for_type(file_type)
            
            if not extractor:
                logger.error(f"‚ùå Type de fichier non support√©: {file_type}")
                return [{'erreur': f"Type de fichier non support√©: {file_type}"}]
            
            # Logger l'extracteur utilis√©
            extractor_name = extractor.__class__.__name__
            logger.info(f"üîß Utilisation de l'extracteur: {extractor_name}")
            
            # Effectuer l'extraction
            extracted_entries = extractor.extract(uploaded_file, file_analysis=file_analysis)
            logger.info(f"‚úÖ Extraction termin√©e avec {extractor_name}: {len(extracted_entries) if extracted_entries else 0} entr√©e(s)")
            
            if not extracted_entries:
                logger.warning("‚ö†Ô∏è Aucune donn√©e extraite")
                return []
            
            # Filtrer les colonnes cibles si sp√©cifi√©es
            if target_columns:
                extracted_entries = self._filter_target_columns(extracted_entries, target_columns)
            
            # Mettre √† jour les m√©triques
            self.performance_metrics['successful_extractions'] += 1
            self.performance_metrics['extraction_by_type'][file_type] += 1
            
            # Calculer le temps d'extraction
            extraction_time = time.time() - start_time
            
            # Mettre √† jour le temps moyen
            if self.performance_metrics['total_extractions'] > 0:
                self.performance_metrics['average_extraction_time'] = (
                    (self.performance_metrics['average_extraction_time'] * 
                     (self.performance_metrics['total_extractions'] - 1) + extraction_time) /
                    self.performance_metrics['total_extractions']
                )
            else:
                self.performance_metrics['average_extraction_time'] = extraction_time
            
            # Enregistrer le temps par type
            if file_type in self.performance_metrics['extraction_time_by_type']:
                self.performance_metrics['extraction_time_by_type'][file_type].append(extraction_time)
            
            # Enrichir avec le post-processeur intelligent (si activ√©)
            if self.intelligent_processor.is_available() and extracted_entries:
                for entry in extracted_entries:
                    if 'valeurs_extraites' in entry:
                        # R√©cup√©rer le texte source si disponible
                        text_source = entry.get('text_source', '')
                        if text_source:
                            enhanced_data = self.intelligent_processor.enhance_extraction(
                                entry['valeurs_extraites'],
                                text_source,
                                context=file_analysis
                            )
                            entry['valeurs_extraites'] = enhanced_data
            
            # Enrichir avec les suggestions depuis la base de donn√©es
            if self.database_learner and self.database_learner.is_trained:
                for entry in extracted_entries:
                    if 'valeurs_extraites' in entry:
                        self._enrich_with_database_suggestions(entry['valeurs_extraites'])
            
            # Les valeurs g√©n√©r√©es (segment, famille) sont d√©j√† cr√©√©es dans generate_missing_values()
            # via les m√©thodes _classify_segment() et _classify_famille() qui utilisent database_learner
            
            # Sauvegarder dans le cache (si cache_key disponible)
            if cache_key:
                try:
                    self.extraction_cache.set(cache_key, extracted_entries)
                except Exception as e:
                    logger.debug(f"Erreur sauvegarde cache: {e}")
            
            logger.info(f"‚úÖ Extraction termin√©e: {len(extracted_entries)} entr√©es en {extraction_time:.2f}s")
            return extracted_entries
            
        except Exception as e:
            self.performance_metrics['extraction_errors'] += 1
            error_type = type(e).__name__
            
            # Logger avec traceback pour debug
            logger.error(
                f"‚ùå Erreur lors de l'extraction ({error_type}): {e}\n"
                f"Traceback: {traceback.format_exc()}"
            )
            
            # Mettre √† jour les m√©triques d'erreur par type
            if 'errors_by_type' not in self.performance_metrics:
                self.performance_metrics['errors_by_type'] = {}
            self.performance_metrics['errors_by_type'][error_type] = \
                self.performance_metrics['errors_by_type'].get(error_type, 0) + 1
            
            return [{
                'erreur': f"Erreur lors de l'extraction: {error_type} - {str(e)}",
                'error_type': error_type,
                'error_details': str(e)
            }]
    
    
    def _get_extractor_for_type(self, file_type: str):
        """
        Retourne l'extracteur appropri√© pour le type de fichier
        
        Args:
            file_type: Type de fichier
            
        Returns:
            Extracteur appropri√© ou None
        """
        extractors = {
            'pdf': self.pdf_extractor,
            'excel': self.excel_extractor,
            'text': self.text_extractor
        }
        
        return extractors.get(file_type)
    
    def _filter_target_columns(self, extracted_entries: List[Dict[str, Any]], target_columns: List[str]) -> List[Dict[str, Any]]:
        """
        Filtre les entr√©es pour ne garder que les colonnes cibles
        
        Args:
            extracted_entries: Entr√©es extraites
            target_columns: Colonnes cibles
            
        Returns:
            Entr√©es filtr√©es
        """
        try:
            filtered_entries = []
            
            for entry in extracted_entries:
                if 'valeurs_extraites' in entry:
                    # Filtrer les valeurs extraites
                    filtered_values = {}
                    for col in target_columns:
                        if col in entry['valeurs_extraites']:
                            filtered_values[col] = entry['valeurs_extraites'][col]
                    
                    # Cr√©er une nouvelle entr√©e avec les valeurs filtr√©es
                    filtered_entry = entry.copy()
                    filtered_entry['valeurs_extraites'] = filtered_values
                    filtered_entries.append(filtered_entry)
                else:
                    # Garder l'entr√©e telle quelle si pas de valeurs_extraites
                    filtered_entries.append(entry)
            
            logger.info(f"üìä Filtrage termin√©: {len(filtered_entries)} entr√©es filtr√©es")
            return filtered_entries
            
        except Exception as e:
            logger.error(f"Erreur filtrage colonnes cibles: {e}")
            return extracted_entries
    
    def validate_extraction(self, data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        Valide une extraction
        
        Args:
            data: Donn√©es √† valider
            
        Returns:
            R√©sultat de validation ou None
        """
        try:
            return self.validation_engine.validate_extraction(data)
        except Exception as e:
            logger.error(f"Erreur validation extraction: {e}")
            return None
    
    def get_patterns_for_field(self, field_name: str) -> List[str]:
        """
        R√©cup√®re les patterns pour un champ
        
        Args:
            field_name: Nom du champ
            
        Returns:
            Liste des patterns
        """
        try:
            return self.pattern_manager.get_field_patterns(field_name)
        except Exception as e:
            logger.error(f"Erreur r√©cup√©ration patterns pour {field_name}: {e}")
            return []
    
    def add_custom_pattern(self, category: str, subcategory: str, pattern: str):
        """
        Ajoute un pattern personnalis√©
        
        Args:
            category: Cat√©gorie du pattern
            subcategory: Sous-cat√©gorie du pattern
            pattern: Pattern regex
        """
        try:
            self.pattern_manager.add_pattern(category, subcategory, pattern)
            logger.info(f"Pattern personnalis√© ajout√©: {category}.{subcategory}")
        except Exception as e:
            logger.error(f"Erreur ajout pattern personnalis√©: {e}")
    
    def detect_lots(self, text: str) -> List[Dict[str, Any]]:
        """
        D√©tecte les lots dans un texte
        
        Args:
            text: Texte √† analyser
            
        Returns:
            Liste des lots d√©tect√©s
        """
        try:
            lots = self.lot_detector.detect_lots(text)
            return [lot.__dict__ for lot in lots]
        except Exception as e:
            logger.error(f"Erreur d√©tection lots: {e}")
            return []
    
    def get_performance_metrics(self) -> Dict[str, Any]:
        """
        Retourne les m√©triques de performance
        
        Returns:
            Dictionnaire des m√©triques
        """
        metrics = self.performance_metrics.copy()
        
        # Ajouter les m√©triques des composants
        metrics['pattern_manager'] = self.pattern_manager.get_performance_stats()
        metrics['validation_engine'] = self.validation_engine.get_performance_metrics()
        metrics['lot_detector'] = self.lot_detector.get_performance_metrics()
        
        return metrics
    
    def reset_metrics(self):
        """Remet √† z√©ro toutes les m√©triques"""
        self.performance_metrics = {
            'total_extractions': 0,
            'successful_extractions': 0,
            'extraction_errors': 0,
            'average_extraction_time': 0.0,
            'extraction_by_type': {
                'pdf': 0,
                'excel': 0,
                'text': 0,
                'other': 0
            },
            'errors_by_type': {},
            'extraction_time_by_type': {
                'pdf': [],
                'excel': [],
                'text': [],
                'other': []
            },
            'field_extraction_stats': {},
            'validation_failure_reasons': {}
        }
        
        self.pattern_manager.reset_stats()
        self.validation_engine.reset_metrics()
        self.lot_detector.reset_metrics()
        
        logger.info("üìä M√©triques remises √† z√©ro")
    
    def _learn_from_reference_data(self):
        """
        Apprend des patterns depuis les donn√©es de r√©f√©rence
        
        Analyse les donn√©es existantes pour extraire des patterns communs
        et am√©liorer la d√©tection future.
        Si une DatabaseManager est disponible, utilise aussi les donn√©es de la BDD.
        """
        try:
            if self.reference_data is None or self.reference_data.empty:
                # Si pas de reference_data mais qu'on a un database_manager, l'utiliser
                if self.database_manager and not self.database_learner.is_trained:
                    logger.info("üìä Pas de reference_data, utilisation directe de la BDD...")
                    self.database_learner.learn_from_database(limit=500)
                return
            
            logger.info(f"üß† Apprentissage depuis {len(self.reference_data)} enregistrements de r√©f√©rence...")
            
            # Analyser les intitul√©s de lots pour extraire des patterns
            if 'intitule_lot' in self.reference_data.columns:
                lots = self.reference_data['intitule_lot'].dropna()
                if not lots.empty:
                    common_words = self._extract_common_words(lots)
                    logger.info(f"üìä {len(common_words)} mots communs extraits depuis les intitul√©s de lots")
            
            # Analyser les montants pour d√©tecter des patterns
            if 'montant_global_estime' in self.reference_data.columns:
                montants = self.reference_data['montant_global_estime'].dropna()
                if not montants.empty:
                    montant_stats = {
                        'min': float(montants.min()),
                        'max': float(montants.max()),
                        'mean': float(montants.mean()),
                        'median': float(montants.median())
                    }
                    logger.info(f"üí∞ Statistiques montants: {montant_stats}")
            
            # Si on a aussi un database_manager, fusionner les apprentissages
            if self.database_manager and not self.database_learner.is_trained:
                logger.info("üìä Enrichissement avec les donn√©es de la BDD...")
                self.database_learner.learn_from_database(limit=500)
            
            logger.info("‚úÖ Apprentissage termin√©")
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erreur lors de l'apprentissage: {e}")
    
    def _enrich_with_database_suggestions(self, extracted_data: Dict[str, Any]):
        """
        Enrichit les donn√©es extraites avec des suggestions depuis la BDD
        NE REMPLACE QUE LES CHAMPS VRAIMENT VIDES - ne modifie pas les valeurs extraites
        
        Args:
            extracted_data: Donn√©es extraites √† enrichir (modifi√© sur place)
        """
        try:
            if not self.database_learner or not self.database_learner.is_trained:
                return
            
            # Champs √† enrichir UNIQUEMENT si compl√®tement manquants ou vides
            # Note: segment et famille sont maintenant g√©n√©r√©s intelligemment dans generate_missing_values()
            fields_to_enrich = ['type_procedure', 'mono_multi', 'univers', 'groupement']
            
            for field in fields_to_enrich:
                # V√©rifier si le champ est vraiment vide (pas pr√©sent, None, ou cha√Æne vide)
                current_value = extracted_data.get(field)
                
                if not current_value or (isinstance(current_value, str) and current_value.strip() == ''):
                    # Sugg√©rer une valeur depuis la BDD
                    suggestion = self.database_learner.suggest_value(field, extracted_data)
                    if suggestion:
                        extracted_data[field] = suggestion
                        logger.debug(f"üí° Valeur sugg√©r√©e depuis BDD pour {field}: {suggestion}")
                else:
                    # Le champ a d√©j√† une valeur - NE PAS la remplacer
                    logger.debug(f"‚úì Champ '{field}' d√©j√† rempli ({current_value}), pas de suggestion")
        
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erreur enrichissement avec suggestions BDD: {e}")
    
    def _extract_common_words(self, series: pd.Series, min_occurrences: int = 3) -> List[str]:
        """
        Extrait les mots communs d'une s√©rie de textes
        
        Args:
            series: S√©rie de textes √† analyser
            min_occurrences: Nombre minimum d'occurrences pour √™tre consid√©r√© comme commun
            
        Returns:
            Liste des mots communs
        """
        try:
            from collections import Counter
            import re
            
            # Joindre tous les textes
            all_text = ' '.join(series.astype(str)).lower()
            
            # Extraire les mots (au moins 3 caract√®res)
            words = re.findall(r'\b[a-zA-Z√Ä-√ø]{3,}\b', all_text)
            
            # Compter les occurrences
            word_counts = Counter(words)
            
            # Filtrer par nombre minimum d'occurrences
            common_words = [
                word for word, count in word_counts.items() 
                if count >= min_occurrences
            ]
            
            return sorted(common_words, key=lambda x: word_counts[x], reverse=True)[:50]
            
        except Exception as e:
            logger.error(f"Erreur extraction mots communs: {e}")
            return []
    
    def save_patterns_config(self, config_file: str):
        """
        Sauvegarde la configuration des patterns
        
        Args:
            config_file: Chemin du fichier de configuration
        """
        try:
            self.pattern_manager.save_to_file(config_file)
            logger.info(f"Configuration patterns sauvegard√©e: {config_file}")
        except Exception as e:
            logger.error(f"Erreur sauvegarde configuration: {e}")
    
    def load_patterns_config(self, config_file: str):
        """
        Charge la configuration des patterns
        
        Args:
            config_file: Chemin du fichier de configuration
        """
        try:
            self.pattern_manager.load_from_file(config_file)
            logger.info(f"Configuration patterns charg√©e: {config_file}")
        except Exception as e:
            logger.error(f"Erreur chargement configuration: {e}")
    
    def get_extraction_summary(self) -> Dict[str, Any]:
        """
        Retourne un r√©sum√© de l'extraction
        
        Returns:
            R√©sum√© de l'extraction
        """
        metrics = self.get_performance_metrics()
        
        return {
            'total_extractions': metrics['total_extractions'],
            'success_rate': (
                metrics['successful_extractions'] / metrics['total_extractions'] * 100
                if metrics['total_extractions'] > 0 else 0
            ),
            'average_time': metrics['average_extraction_time'],
            'extraction_by_type': metrics['extraction_by_type'],
            'pattern_compilations': metrics['pattern_manager']['total_compilations'],
            'validation_success_rate': (
                metrics['validation_engine']['successful_validations'] / 
                metrics['validation_engine']['total_validations'] * 100
                if metrics['validation_engine']['total_validations'] > 0 else 0
            ),
            'lot_detection_success_rate': (
                metrics['lot_detector']['successful_detections'] / 
                metrics['lot_detector']['total_detections'] * 100
                if metrics['lot_detector']['total_detections'] > 0 else 0
            ),
            'cache_stats': self.extraction_cache.get_stats()
        }
    
    def get_quality_metrics(self, extracted_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Calcule des m√©triques de qualit√© d√©taill√©es pour les donn√©es extraites
        
        Args:
            extracted_data: Donn√©es extraites √† √©valuer
            
        Returns:
            Dictionnaire des m√©triques de qualit√©
        """
        try:
            total_fields = len(extracted_data)
            filled_fields = sum(1 for v in extracted_data.values() if v and str(v).strip())
            completeness_score = (filled_fields / total_fields * 100) if total_fields > 0 else 0
            
            # Calculer la confiance bas√©e sur la validation
            validation_result = self.validate_extraction(extracted_data)
            confidence_score = validation_result.confidence * 100 if validation_result else 0
            
            # Calculer la pr√©cision des champs (bas√© sur les validations de champs)
            field_accuracy = {}
            if validation_result and validation_result.field_validations:
                for field, validation in validation_result.field_validations.items():
                    field_accuracy[field] = {
                        'valid': validation.get('valid', False),
                        'confidence': validation.get('confidence', 0.0) * 100
                    }
            
            # √âvaluer la qualit√© du document
            document_quality = 'high' if confidence_score >= 80 else 'medium' if confidence_score >= 60 else 'low'
            
            # D√©terminer si une revue est recommand√©e
            needs_review = (
                confidence_score < 70 or 
                completeness_score < 50 or
                (validation_result and len(validation_result.errors) > 0)
            )
            
            return {
                'completeness_score': round(completeness_score, 2),
                'confidence_score': round(confidence_score, 2),
                'field_accuracy': field_accuracy,
                'document_quality': document_quality,
                'needs_review': needs_review,
                'total_fields': total_fields,
                'filled_fields': filled_fields,
                'validation_issues': len(validation_result.issues) if validation_result else 0,
                'validation_errors': len(validation_result.errors) if validation_result else 0,
                'validation_warnings': len(validation_result.warnings) if validation_result else 0,
                'auto_corrections': validation_result.metadata.get('auto_corrections', []) if validation_result else []
            }
            
        except Exception as e:
            logger.error(f"Erreur calcul m√©triques qualit√©: {e}")
            return {
                'completeness_score': 0.0,
                'confidence_score': 0.0,
                'field_accuracy': {},
                'document_quality': 'unknown',
                'needs_review': True,
                'error': str(e)
        }
    
    def __str__(self) -> str:
        """Repr√©sentation string de l'extracteur"""
        metrics = self.get_performance_metrics()
        return f"AOExtractorV2(extractions={metrics['total_extractions']}, success_rate={self.get_extraction_summary()['success_rate']:.1f}%)"
    
    def __repr__(self) -> str:
        """Repr√©sentation d√©taill√©e de l'extracteur"""
        return f"AOExtractorV2(pattern_manager={self.pattern_manager}, validation_engine={self.validation_engine})"

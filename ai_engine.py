"""
ü§ñ Moteur IA Avanc√© - Veille Concurrentielle
===========================================

Moteur d'IA complet capable de r√©pondre √† n'importe quelle question sur la base de donn√©es :
- Statistiques avanc√©es
- Filtrage intelligent
- Affichage de donn√©es
- Analyses crois√©es
- D√©tection automatique d'intention
"""

import pandas as pd
import numpy as np
from typing import List, Dict, Any, Optional, Union, Tuple
import logging
from datetime import datetime
import re
import sqlite3

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class VeilleAIEngine:
    """Moteur d'IA avanc√© pour l'analyse de veille concurrentielle"""
    
    # Colonnes de la base de donn√©es
    COLONNES_DB = {
        'identifiants': ['id', 'reference_procedure', 'lot_numero'],
        'classification': ['mots_cles', 'univers', 'segment', 'famille', 'statut', 'groupement'],
        'procedure': ['type_procedure', 'mono_multi', 'execution_marche', 'nbr_lots', 'intitule_procedure', 'intitule_lot'],
        'dates': ['date_limite', 'date_attribution', 'duree_marche', 'reconduction', 'fin_sans_reconduction', 'fin_avec_reconduction'],
        'financier': ['montant_global_estime', 'montant_global_maxi', 'achat', 'credit_bail', 'credit_bail_duree', 'location', 'location_duree', 'mad'],
        'quantites': ['quantite_minimum', 'quantites_estimees', 'quantite_maximum'],
        'criteres': ['criteres_economique', 'criteres_techniques', 'autres_criteres', 'rse', 'contribution_fournisseur'],
        'resultats': ['attributaire', 'produit_retenu'],
        'notes': ['infos_complementaires', 'remarques', 'notes_acheteur_procedure', 'notes_acheteur_fournisseur', 'notes_acheteur_positionnement', 'note_veille'],
        'metadata': ['created_at', 'updated_at']
    }
    
    # Synonymes pour mieux comprendre les questions
    SYNONYMES = {
        'montant': ['montant', 'budget', 'prix', 'co√ªt', 'cout', 'valeur', 'financier', 'euro', '‚Ç¨'],
        'date': ['date', 'quand', 'p√©riode', 'periode', 'ann√©e', 'annee', 'mois', 'jour'],
        'groupement': ['groupement', 'organisme', 'organisation', 'acheteur', 'entit√©', 'entite'],
        'univers': ['univers', 'domaine', 'secteur', 'cat√©gorie', 'categorie'],
        'statut': ['statut', '√©tat', 'etat', 'status', 'situation'],
        'lot': ['lot', 'lots', 'nbr_lots', 'nombre de lots'],
        'attributaire': ['attributaire', 'gagnant', 'fournisseur', 'entreprise', 'soci√©t√©', 'societe', 'titulaire'],
        'procedure': ['proc√©dure', 'procedure', 'appel', 'ao', 'march√©', 'marche'],
    }
    
    def __init__(self):
        self.initialized = False
        self.data = None
        self.conversation_history = []
        self.db_connection = None
        
        # M√©triques de performance
        self.performance_metrics = {
            'total_questions': 0,
            'successful_answers': 0,
            'failed_answers': 0,
            'average_response_time': 0,
            'cache_hits': 0,
            'cache_misses': 0
        }
        
        # Cache des r√©sultats
        self.cache = {}
        
    def initialize(self, data: pd.DataFrame, load_heavy_models: bool = False):
        """Initialise le moteur d'IA avec les donn√©es"""
        try:
            logger.info("üöÄ Initialisation du moteur d'IA avanc√©...")
            self.data = data.copy()
            
            # Pr√©traitement des donn√©es
            self._preprocess_data()
            
            self.initialized = True
            logger.info(f"‚úÖ Moteur d'IA initialis√© avec {len(self.data)} enregistrements!")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'initialisation: {e}")
            raise
    
    def _preprocess_data(self):
        """Pr√©traite les donn√©es pour optimiser les analyses"""
        try:
            # Convertir les colonnes num√©riques
            numeric_cols = ['montant_global_estime', 'montant_global_maxi', 'duree_marche', 
                          'nbr_lots', 'lot_numero', 'quantite_minimum', 'quantites_estimees', 
                          'quantite_maximum', 'credit_bail_duree', 'location_duree']
            
            for col in numeric_cols:
                if col in self.data.columns:
                    self.data[col] = pd.to_numeric(self.data[col], errors='coerce')
            
            # Convertir les colonnes de dates
            date_cols = ['date_limite', 'date_attribution', 'fin_sans_reconduction', 'fin_avec_reconduction']
            for col in date_cols:
                if col in self.data.columns:
                    self.data[col] = pd.to_datetime(self.data[col], errors='coerce')
            
            # Nettoyer les colonnes texte
            text_cols = self.data.select_dtypes(include=['object']).columns
            for col in text_cols:
                self.data[col] = self.data[col].fillna('').astype(str).str.strip()
            
            logger.info("‚úÖ Donn√©es pr√©trait√©es avec succ√®s")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur pr√©traitement: {e}")
    
    def ask_question(self, question: str) -> str:
        """R√©pond intelligemment √† n'importe quelle question avec contexte conversationnel"""
        if not self.initialized:
            return "‚ùå Le moteur d'IA n'est pas initialis√©. Veuillez d'abord l'initialiser."
        
        start_time = datetime.now()
        
        try:
            logger.info(f"ü§î Question pos√©e: {question}")
            self.performance_metrics['total_questions'] += 1
            
            # V√©rifier le cache (d√©sactiv√© pour les questions contextuelles)
            cache_key = question.lower().strip()
            is_contextual = self._is_contextual_question(question)
            
            if not is_contextual and cache_key in self.cache:
                self.performance_metrics['cache_hits'] += 1
                logger.info("üíæ R√©ponse trouv√©e dans le cache")
                return self.cache[cache_key]
            
            self.performance_metrics['cache_misses'] += 1
            
            # Enrichir la question avec le contexte si n√©cessaire
            enriched_question = self._enrich_with_context(question)
            logger.info(f"üìù Question enrichie: {enriched_question}")
            
            # Analyser la question et d√©terminer l'intention
            intention = self._detect_intention(enriched_question)
            logger.info(f"üéØ Intention d√©tect√©e: {intention['type']}")
            
            # Router vers la bonne m√©thode selon l'intention
            response = self._route_question(enriched_question, intention)
            
            # Ajouter un indicateur si la question √©tait contextuelle
            if is_contextual and enriched_question != question:
                response = f"üîó *Question interpr√©t√©e: \"{enriched_question}\"*\n\n{response}"
            
            # Mettre en cache seulement si pas contextuel
            if not is_contextual:
                self.cache[cache_key] = response
            
            # Ajouter √† l'historique
            self.conversation_history.append({
                'question': question,
                'enriched_question': enriched_question,
                'response': response,
                'intention': intention,
                'timestamp': datetime.now(),
                'filters': intention.get('filters', {}),
                'is_contextual': is_contextual
            })
            
            # Mettre √† jour les m√©triques
            self.performance_metrics['successful_answers'] += 1
            elapsed_time = (datetime.now() - start_time).total_seconds()
            self._update_average_response_time(elapsed_time)
            
            return response
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du traitement de la question: {e}")
            self.performance_metrics['failed_answers'] += 1
            return f"‚ùå D√©sol√©, une erreur est survenue: {str(e)}\n\nüí° Essayez de reformuler votre question."
    
    def _is_contextual_question(self, question: str) -> bool:
        """D√©tecte si la question fait r√©f√©rence au contexte pr√©c√©dent"""
        question_lower = question.lower().strip()
        
        # Mots-cl√©s indiquant une r√©f√©rence contextuelle
        contextual_keywords = [
            'ceux de', 'celles de', 'celui de', 'celle de',
            'pour lui', 'pour eux', 'pour elles',
            'et pour', 'et avec', 'et du', 'et de', 'et le', 'et la', 'et les',
            'aussi', '√©galement', 'm√™me chose',
            'compare avec', 'compar√© √†', 'par rapport √†',
            'maintenant', 'ensuite', 'puis', 'apr√®s',
            'et celui', 'et celle', 'et ceux', 'et celles',
            'm√™me pour', 'idem pour',
            'pareil pour', 'identique pour'
        ]
        
        # Pronoms d√©monstratifs et possessifs
        pronouns = ['il', 'elle', 'ils', 'elles', 'le', 'la', 'les', 'leur', 'leurs', 'lui', 'eux']
        
        # V√©rifier les mots-cl√©s contextuels
        for keyword in contextual_keywords:
            if keyword in question_lower:
                return True
        
        # Questions tr√®s courtes qui semblent contextuelles
        words = question_lower.split()
        if len(words) <= 5:
            # V√©rifier les pronoms
            for pronoun in pronouns:
                if pronoun in words:
                    return True
            
            # V√©rifier les univers/groupements connus
            known_entities = ['resah', 'uniha', 'ugap', 'm√©dical', 'medical', 'informatique', 'mobilier', 'en cours', 'attribu√©', 'attribue']
            for entity in known_entities:
                if entity in question_lower:
                    return True
        
        # Questions commen√ßant par "et"
        if question_lower.startswith('et '):
            return True
        
        # Questions tr√®s courtes avec "en" (ex: "en m√©dical", "en informatique")
        if len(words) <= 3 and any(word in question_lower for word in ['en m√©dical', 'en medical', 'en informatique', 'en mobilier']):
            return True
        
        # Questions avec "pour" + entit√© connue
        if 'pour' in question_lower and any(entity in question_lower for entity in ['resah', 'uniha', 'ugap', 'm√©dical', 'medical', 'informatique']):
            return True
        
        return False
    
    def _enrich_with_context(self, question: str) -> str:
        """Enrichit la question avec le contexte de la conversation pr√©c√©dente"""
        if not self.conversation_history:
            return question
        
        question_lower = question.lower()
        
        # R√©cup√©rer le dernier √©change
        last_exchange = self.conversation_history[-1]
        last_filters = last_exchange.get('filters', {})
        last_intention = last_exchange.get('intention', {})
        
        # Si la question ne semble pas contextuelle, retourner telle quelle
        if not self._is_contextual_question(question):
            return question
        
        logger.info(f"üîó Question contextuelle d√©tect√©e. Contexte pr√©c√©dent: {last_filters}")
        
        enriched = question
        
        # G√©rer les r√©f√©rences directes √† un autre groupement/univers/etc
        # Ex: "et pour l'UNIHA" -> "montre les lots pour l'UNIHA"
        if any(phrase in question_lower for phrase in ['et pour', 'et du', 'et de', 'et le', 'et la', 'et avec']):
            # Extraire le nouveau sujet
            new_subject = self._extract_subject_from_contextual(question)
            if new_subject:
                # Reconstruire la question avec l'action de la question pr√©c√©dente
                last_question = last_exchange.get('question', '')
                action = self._extract_action(last_question)
                enriched = f"{action} {new_subject}"
                logger.info(f"‚ú® Question reconstruite: {enriched}")
        
        # G√©rer "ceux de" / "celles de"
        elif any(phrase in question_lower for phrase in ['ceux de', 'celles de', 'celui de', 'celle de']):
            # Ex: "ceux de l'UNIHA" -> on remplace le filtre pr√©c√©dent
            new_subject = question_lower.split('de ')[-1].strip()
            last_question = last_exchange.get('question', '')
            action = self._extract_action(last_question)
            enriched = f"{action} {new_subject}"
            logger.info(f"‚ú® Question reconstruite: {enriched}")
        
        # G√©rer les comparaisons
        elif any(phrase in question_lower for phrase in ['compare avec', 'compar√© √†', 'par rapport √†']):
            # Ex: "compare avec l'UNIHA" -> "compare RESAH et UNIHA"
            if last_filters.get('groupement'):
                new_subject = question_lower.split('avec ')[-1].strip() if 'avec' in question_lower else question_lower.split('√† ')[-1].strip()
                enriched = f"compare {last_filters['groupement']} et {new_subject}"
                logger.info(f"‚ú® Comparaison reconstruite: {enriched}")
        
        # G√©rer "m√™me chose pour" / "pareil pour"
        elif any(phrase in question_lower for phrase in ['m√™me chose', 'pareil pour', 'idem pour', 'identique pour']):
            new_subject = question_lower.split('pour ')[-1].strip() if 'pour' in question_lower else ''
            last_question = last_exchange.get('question', '')
            action = self._extract_action(last_question)
            enriched = f"{action} {new_subject}"
            logger.info(f"‚ú® Question reconstruite: {enriched}")
        
        # G√©rer les questions tr√®s courtes (h√©riter des filtres pr√©c√©dents mais avec nouveau sujet)
        elif len(question.split()) <= 5:
            # Essayer d'identifier le nouveau filtre dans la question courte
            new_filter = self._extract_new_filter(question)
            if new_filter and last_intention.get('action'):
                last_question = last_exchange.get('question', '')
                action = self._extract_action(last_question)
                
                # Construire la question en combinant les filtres pr√©c√©dents + nouveau filtre
                enriched_parts = [action]
                
                # Garder les filtres pr√©c√©dents et ajouter le nouveau
                if 'groupement' in new_filter:
                    # Remplacer le groupement pr√©c√©dent par le nouveau
                    enriched_parts.append(new_filter['groupement'])
                    # Garder l'univers pr√©c√©dent s'il existe
                    if last_filters.get('univers'):
                        enriched_parts.append(last_filters['univers'])
                elif 'univers' in new_filter:
                    # Garder le groupement pr√©c√©dent et remplacer l'univers
                    if last_filters.get('groupement'):
                        enriched_parts.append(last_filters['groupement'])
                    enriched_parts.append(new_filter['univers'])
                elif 'statut' in new_filter:
                    # Garder groupement et univers pr√©c√©dents, ajouter le statut
                    if last_filters.get('groupement'):
                        enriched_parts.append(last_filters['groupement'])
                    if last_filters.get('univers'):
                        enriched_parts.append(last_filters['univers'])
                    enriched_parts.append(new_filter['statut'])
                else:
                    enriched = f"{action} {question}"
                
                if 'enriched_parts' in locals():
                    enriched = ' '.join(enriched_parts)
                
                logger.info(f"‚ú® Question courte enrichie (filtres combin√©s): {enriched}")
        
        # G√©rer les questions avec "en" (ex: "en m√©dical", "en informatique")
        elif any(phrase in question_lower for phrase in ['en m√©dical', 'en medical', 'en informatique', 'en mobilier']):
            last_question = last_exchange.get('question', '')
            action = self._extract_action(last_question)
            
            # Construire la question en gardant les filtres pr√©c√©dents + nouveau filtre univers
            enriched_parts = [action]
            
            # Garder le groupement pr√©c√©dent s'il existe
            if last_filters.get('groupement'):
                enriched_parts.append(last_filters['groupement'])
            
            # Ajouter le nouvel univers
            if 'en m√©dical' in question_lower or 'en medical' in question_lower:
                enriched_parts.append('m√©dical')
            elif 'en informatique' in question_lower:
                enriched_parts.append('informatique')
            elif 'en mobilier' in question_lower:
                enriched_parts.append('mobilier')
            
            # Garder le statut pr√©c√©dent s'il existe
            if last_filters.get('statut'):
                enriched_parts.append(last_filters['statut'])
            
            enriched = ' '.join(enriched_parts)
            logger.info(f"‚ú® Question 'en' enrichie (filtres combin√©s): {enriched}")
        
        return enriched
    
    def _extract_action(self, question: str) -> str:
        """Extrait l'action principale d'une question"""
        question_lower = question.lower()
        
        if any(word in question_lower for word in ['montre', 'affiche', 'voir']):
            return 'montre les lots pour'
        elif any(word in question_lower for word in ['liste', 'lister']):
            return 'liste les lots pour'
        elif any(word in question_lower for word in ['combien', 'nombre']):
            return 'combien de lots pour'
        elif any(word in question_lower for word in ['somme', 'total montant']):
            return 'somme des montants pour'
        elif any(word in question_lower for word in ['moyenne', 'moyen']):
            return 'montant moyen pour'
        elif any(word in question_lower for word in ['analyse', 'statistique']):
            return 'analyse pour'
        else:
            return 'montre les lots pour'
    
    def _extract_subject_from_contextual(self, question: str) -> str:
        """Extrait le sujet d'une question contextuelle"""
        question_lower = question.lower()
        
        # Supprimer les mots de liaison
        for phrase in ['et pour', 'et du', 'et de', 'et le', 'et la', 'et avec', 'ceux de', 'celles de']:
            if phrase in question_lower:
                subject = question_lower.split(phrase)[-1].strip()
                return subject
        
        return question_lower.strip()
    
    def _extract_new_filter(self, question: str) -> Dict[str, str]:
        """Extrait le nouveau filtre d'une question courte"""
        question_lower = question.lower()
        new_filter = {}
        
        # D√©tecter les groupements
        if 'resah' in question_lower:
            new_filter['groupement'] = 'RESAH'
        elif 'uniha' in question_lower:
            new_filter['groupement'] = 'UNIHA'
        elif 'ugap' in question_lower:
            new_filter['groupement'] = 'UGAP'
        
        # D√©tecter les univers
        if any(word in question_lower for word in ['m√©dical', 'medical']):
            new_filter['univers'] = 'M√©dical'
        elif 'informatique' in question_lower:
            new_filter['univers'] = 'Informatique'
        elif 'mobilier' in question_lower:
            new_filter['univers'] = 'Mobilier'
        
        # D√©tecter les statuts
        if 'en cours' in question_lower:
            new_filter['statut'] = 'En cours'
        elif any(word in question_lower for word in ['attribu√©', 'attribue']):
            new_filter['statut'] = 'Attribu√©'
        
        return new_filter
    
    def _extract_base_question(self, question: str, filters: Dict[str, Any]) -> str:
        """Extrait la question de base sans les filtres sp√©cifiques"""
        # Simplifier en retournant la question telle quelle
        # Les filtres seront d√©tect√©s √† nouveau
        return question
    
    def _detect_intention(self, question: str) -> Dict[str, Any]:
        """D√©tecte l'intention de la question"""
        question_lower = question.lower()
        
        intention = {
            'type': 'general',
            'action': None,
            'entities': [],
            'filters': {},
            'aggregation': None
        }
        
        # Si c'est une recherche sp√©cifique, ignorer les filtres g√©n√©raux
        if self._should_skip_filters_for_search(question):
            intention['skip_general_filters'] = True
        
        # D√©tection de l'action principale
        if any(word in question_lower for word in ['combien', 'nombre', 'total', 'compter', 'compte', 'nb', 'quantit√©']):
            intention['type'] = 'count'
            intention['action'] = 'compter'
        
        elif any(word in question_lower for word in ['somme', 'total montant', 'budget total', 'additionner']):
            intention['type'] = 'sum'
            intention['action'] = 'sommer'
        
        elif any(word in question_lower for word in ['moyenne', 'moyen', 'mean', 'avg']):
            intention['type'] = 'average'
            intention['action'] = 'moyenner'
        
        elif any(word in question_lower for word in ['maximum', 'max', 'plus grand', 'plus √©lev√©', 'plus eleve']):
            intention['type'] = 'max'
            intention['action'] = 'maximum'
        
        elif any(word in question_lower for word in ['minimum', 'min', 'plus petit', 'plus bas', 'moins']):
            intention['type'] = 'min'
            intention['action'] = 'minimum'
        
        elif any(word in question_lower for word in ['liste', 'montre', 'affiche', 'voir', 'donne', 'trouve', 'cherche', 'recherche']):
            intention['type'] = 'list'
            intention['action'] = 'lister'
        
        elif any(word in question_lower for word in ['r√©partition', 'repartition', 'distribution', 'grouper', 'group by', 'par']):
            intention['type'] = 'distribution'
            intention['action'] = 'r√©partir'
        
        elif any(word in question_lower for word in ['compare', 'comparaison', 'diff√©rence', 'difference', 'vs', 'versus']):
            intention['type'] = 'comparison'
            intention['action'] = 'comparer'
        
        elif any(word in question_lower for word in ['analyse', 'statistique', 'stat', 'r√©sum√©', 'resume', 'overview']):
            intention['type'] = 'analysis'
            intention['action'] = 'analyser'
        
        elif any(phrase in question_lower for phrase in ['fin de march√©', 'fin de marche', 'expire', 'se termine', 'bient√¥t', 'prochainement', 'proche']):
            if any(word in question_lower for word in ['bient√¥t', 'proche', 'prochainement', 'expire', 'se termine']):
                intention['type'] = 'expiring_lots'
                intention['action'] = 'expiration'
        
        elif any(word in question_lower for word in ['bonjour', 'salut', 'hello', 'hi', 'merci', 'au revoir']):
            intention['type'] = 'conversation'
            intention['action'] = 'converser'
        
        # Extraction des entit√©s (colonnes, valeurs)
        intention['entities'] = self._extract_entities(question_lower)
        
        # Extraction des filtres (seulement si ce n'est pas une recherche sp√©cifique)
        if not intention.get('skip_general_filters', False):
            intention['filters'] = self._extract_filters(question_lower)
        
        # D√©tection d'agr√©gation
        intention['aggregation'] = self._detect_aggregation(question_lower)
        
        return intention
    
    def _extract_entities(self, question: str) -> List[str]:
        """Extrait les entit√©s (colonnes) mentionn√©es dans la question"""
        entities = []
        
        # Chercher les colonnes mentionn√©es
        all_columns = [col for cat in self.COLONNES_DB.values() for col in cat]
        
        for col in all_columns:
            col_variants = [col, col.replace('_', ' '), col.replace('_', '')]
            if any(variant in question for variant in col_variants):
                entities.append(col)
        
        # Chercher via les synonymes
        for key, synonyms in self.SYNONYMES.items():
            if any(syn in question for syn in synonyms):
                # Trouver les colonnes correspondantes
                for col in all_columns:
                    if key in col or col in key:
                        if col not in entities:
                            entities.append(col)
        
        return entities
    
    def _extract_filters(self, question: str) -> Dict[str, Any]:
        """Extrait les filtres de la question"""
        filters = {}
        question_lower = question.lower()
        
        # D√©tecter les groupements sp√©cifiques
        if 'resah' in question_lower:
            filters['groupement'] = 'RESAH'
        elif 'uniha' in question_lower:
            filters['groupement'] = 'UNIHA'
        elif 'ugap' in question_lower:
            filters['groupement'] = 'UGAP'
        
        # D√©tecter les univers
        if any(word in question_lower for word in ['m√©dical', 'medical', 'sant√©', 'sante']):
            filters['univers'] = 'M√©dical'
        elif 'informatique' in question_lower or 'it' in question_lower:
            filters['univers'] = 'Informatique'
        elif 'mobilier' in question_lower or 'meuble' in question_lower:
            filters['univers'] = 'Mobilier'
        
        # D√©tecter les statuts
        if any(word in question_lower for word in ['en cours', 'actif', 'actifs']):
            filters['statut'] = 'En cours'
        elif any(word in question_lower for word in ['attribu√©', 'attribue', 'termin√©', 'termine']):
            filters['statut'] = 'Attribu√©'
        elif any(word in question_lower for word in ['annul√©', 'annule', 'infructueux']):
            filters['statut'] = 'Annul√©'
        
        # D√©tecter les ann√©es
        year_pattern = r'20\d{2}'
        years = re.findall(year_pattern, question_lower)
        if years:
            filters['year'] = int(years[0])
        
        # D√©tecter les plages de montants
        montant_pattern = r'(\d+[\s,.]?\d*)\s*(?:‚Ç¨|euros?|k‚Ç¨|M‚Ç¨)'
        montants = re.findall(montant_pattern, question_lower)
        if montants:
            try:
                montant = float(montants[0].replace(' ', '').replace(',', '.'))
                if 'k‚Ç¨' in question_lower:
                    montant *= 1000
                elif 'M‚Ç¨' in question_lower:
                    montant *= 1000000
                
                if any(word in question_lower for word in ['sup√©rieur', 'superieur', 'plus de', 'au-dessus', 'au dessus', '>']):
                    filters['montant_min'] = montant
                elif any(word in question_lower for word in ['inf√©rieur', 'inferieur', 'moins de', 'en-dessous', 'en dessous', '<']):
                    filters['montant_max'] = montant
                else:
                    filters['montant_approx'] = montant
            except:
                pass
        
        return filters
    
    def _detect_aggregation(self, question: str) -> Optional[str]:
        """D√©tecte si la question demande une agr√©gation par colonne"""
        if any(phrase in question for phrase in ['par univers', 'par groupement', 'par statut', 'par segment', 'par famille']):
            if 'univers' in question:
                return 'univers'
            elif 'groupement' in question:
                return 'groupement'
            elif 'statut' in question:
                return 'statut'
            elif 'segment' in question:
                return 'segment'
            elif 'famille' in question:
                return 'famille'
        return None
    
    def _route_question(self, question: str, intention: Dict[str, Any]) -> str:
        """Route la question vers la bonne m√©thode de traitement"""
        
        if intention['type'] == 'conversation':
            return self._handle_conversation(question)
        
        elif intention['type'] == 'count':
            return self._handle_count(question, intention)
        
        elif intention['type'] == 'sum':
            return self._handle_sum(question, intention)
        
        elif intention['type'] == 'average':
            return self._handle_average(question, intention)
        
        elif intention['type'] == 'max':
            return self._handle_max(question, intention)
        
        elif intention['type'] == 'min':
            return self._handle_min(question, intention)
        
        elif intention['type'] == 'list':
            return self._handle_list(question, intention)
        
        elif intention['type'] == 'distribution':
            return self._handle_distribution(question, intention)
        
        elif intention['type'] == 'comparison':
            return self._handle_comparison(question, intention)
        
        elif intention['type'] == 'analysis':
            return self._handle_analysis(question, intention)
        
        elif intention['type'] == 'expiring_lots':
            return self._handle_expiring_lots(question, intention)
        
        else:
            return self._handle_general(question, intention)
    
    def _apply_filters(self, df: pd.DataFrame, filters: Dict[str, Any]) -> pd.DataFrame:
        """Applique les filtres au DataFrame"""
        filtered_df = df.copy()
        
        for key, value in filters.items():
            if key == 'groupement' and 'groupement' in filtered_df.columns:
                filtered_df = filtered_df[filtered_df['groupement'].str.contains(value, case=False, na=False)]
            
            elif key == 'univers' and 'univers' in filtered_df.columns:
                filtered_df = filtered_df[filtered_df['univers'].str.contains(value, case=False, na=False)]
            
            elif key == 'statut' and 'statut' in filtered_df.columns:
                filtered_df = filtered_df[filtered_df['statut'].str.contains(value, case=False, na=False)]
            
            elif key == 'year' and 'date_limite' in filtered_df.columns:
                filtered_df = filtered_df[filtered_df['date_limite'].dt.year == value]
            
            elif key == 'montant_min' and 'montant_global_estime' in filtered_df.columns:
                filtered_df = filtered_df[filtered_df['montant_global_estime'] >= value]
            
            elif key == 'montant_max' and 'montant_global_estime' in filtered_df.columns:
                filtered_df = filtered_df[filtered_df['montant_global_estime'] <= value]
            
            elif key == 'montant_approx' and 'montant_global_estime' in filtered_df.columns:
                # Rechercher les montants proches (¬±20%)
                margin = value * 0.2
                filtered_df = filtered_df[
                    (filtered_df['montant_global_estime'] >= value - margin) &
                    (filtered_df['montant_global_estime'] <= value + margin)
                ]
        
        return filtered_df
    
    def _handle_count(self, question: str, intention: Dict[str, Any]) -> str:
        """G√®re les questions de comptage"""
        try:
            df = self._apply_filters(self.data, intention['filters'])
            
            if len(df) == 0:
                return "‚ùå Aucun enregistrement ne correspond √† vos crit√®res."
            
            # Si agr√©gation demand√©e
            if intention['aggregation']:
                col = intention['aggregation']
                if col in df.columns:
                    counts = df[col].value_counts()
                    
                    response = f"üìä **R√©partition par {col}:**\n\n"
                    for val, count in counts.items():
                        if val and str(val).strip():
                            response += f"- **{val}**: {count} lots\n"
                    
                    response += f"\n**Total**: {len(df)} lots"
                return response
            
            # Comptage simple
            filters_desc = self._describe_filters(intention['filters'])
            response = f"üìä **R√©sultat du comptage**\n\n"
            
            if filters_desc:
                response += f"**Filtres appliqu√©s**: {filters_desc}\n\n"
            
            response += f"**Nombre total de lots**: {len(df)}\n"
            
            # Ajouter des statistiques suppl√©mentaires
            if 'univers' in df.columns:
                top_univers = df['univers'].value_counts().head(3)
                response += f"\n**Top 3 univers**:\n"
                for univ, count in top_univers.items():
                    if univ and str(univ).strip():
                        response += f"- {univ}: {count}\n"
            
                return response
            
        except Exception as e:
            logger.error(f"‚ùå Erreur comptage: {e}")
            return f"‚ùå Erreur lors du comptage: {str(e)}"
    
    def _handle_sum(self, question: str, intention: Dict[str, Any]) -> str:
        """G√®re les questions de somme"""
        try:
            df = self._apply_filters(self.data, intention['filters'])
            
            if len(df) == 0:
                return "‚ùå Aucun enregistrement ne correspond √† vos crit√®res."
            
            # D√©terminer la colonne √† sommer
            if 'montant_global_estime' in df.columns:
                col = 'montant_global_estime'
            elif 'montant_global_maxi' in df.columns:
                col = 'montant_global_maxi'
            else:
                return "‚ùå Aucune colonne de montant trouv√©e."
            
            total = df[col].sum()
            filters_desc = self._describe_filters(intention['filters'])
            
            response = f"üí∞ **Analyse financi√®re**\n\n"
            
            if filters_desc:
                response += f"**Filtres appliqu√©s**: {filters_desc}\n\n"
            
            response += f"**Montant total**: {total:,.2f} ‚Ç¨\n"
            response += f"**Nombre de lots**: {len(df)}\n"
            
            # Ajouter la r√©partition si agr√©gation demand√©e
            if intention['aggregation']:
                agg_col = intention['aggregation']
                if agg_col in df.columns:
                    grouped = df.groupby(agg_col)[col].sum().sort_values(ascending=False)
                    response += f"\n**R√©partition par {agg_col}**:\n"
                    for val, amount in grouped.head(10).items():
                        if val and str(val).strip():
                            response += f"- **{val}**: {amount:,.2f} ‚Ç¨\n"
            
            return response
            
        except Exception as e:
            logger.error(f"‚ùå Erreur somme: {e}")
            return f"‚ùå Erreur lors du calcul de la somme: {str(e)}"
    
    def _handle_average(self, question: str, intention: Dict[str, Any]) -> str:
        """G√®re les questions de moyenne"""
        try:
            df = self._apply_filters(self.data, intention['filters'])
            
            if len(df) == 0:
                return "‚ùå Aucun enregistrement ne correspond √† vos crit√®res."
            
            # D√©terminer la colonne pour la moyenne
            if 'montant_global_estime' in df.columns:
                col = 'montant_global_estime'
            elif 'duree_marche' in df.columns and 'dur√©e' in question.lower():
                col = 'duree_marche'
            else:
                col = 'montant_global_estime'
            
            if col not in df.columns:
                return "‚ùå Colonne non trouv√©e pour calculer la moyenne."
            
            avg = df[col].mean()
            median = df[col].median()
            filters_desc = self._describe_filters(intention['filters'])
            
            response = f"üìä **Analyse statistique - {col.replace('_', ' ').title()}**\n\n"
            
            if filters_desc:
                response += f"**Filtres appliqu√©s**: {filters_desc}\n\n"
            
            if 'montant' in col:
                response += f"**Moyenne**: {avg:,.2f} ‚Ç¨\n"
                response += f"**M√©diane**: {median:,.2f} ‚Ç¨\n"
            else:
                response += f"**Moyenne**: {avg:.2f}\n"
                response += f"**M√©diane**: {median:.2f}\n"
            
            response += f"**Nombre de lots**: {len(df)}\n"
            
            # Ajouter la r√©partition si agr√©gation demand√©e
            if intention['aggregation']:
                agg_col = intention['aggregation']
                if agg_col in df.columns:
                    grouped = df.groupby(agg_col)[col].mean().sort_values(ascending=False)
                    response += f"\n**Moyenne par {agg_col}**:\n"
                    for val, amount in grouped.head(10).items():
                        if val and str(val).strip():
                            if 'montant' in col:
                                response += f"- **{val}**: {amount:,.2f} ‚Ç¨\n"
                            else:
                                response += f"- **{val}**: {amount:.2f}\n"
            
            return response
            
        except Exception as e:
            logger.error(f"‚ùå Erreur moyenne: {e}")
            return f"‚ùå Erreur lors du calcul de la moyenne: {str(e)}"
    
    def _handle_max(self, question: str, intention: Dict[str, Any]) -> str:
        """G√®re les questions de maximum"""
        try:
            df = self._apply_filters(self.data, intention['filters'])
            
            if len(df) == 0:
                return "‚ùå Aucun enregistrement ne correspond √† vos crit√®res."
            
            # D√©terminer la colonne
            if 'montant_global_estime' in df.columns:
                col = 'montant_global_estime'
            else:
                return "‚ùå Colonne non trouv√©e."
            
            max_val = df[col].max()
            max_row = df[df[col] == max_val].iloc[0]
            
            response = f"üìà **Maximum trouv√©**\n\n"
            response += f"**Valeur maximum**: {max_val:,.2f} ‚Ç¨\n\n"
            response += f"**D√©tails du lot**:\n"
            
            if 'intitule_lot' in max_row:
                response += f"- **Intitul√©**: {max_row['intitule_lot']}\n"
            if 'groupement' in max_row:
                response += f"- **Groupement**: {max_row['groupement']}\n"
            if 'univers' in max_row:
                response += f"- **Univers**: {max_row['univers']}\n"
            if 'reference_procedure' in max_row:
                response += f"- **R√©f√©rence**: {max_row['reference_procedure']}\n"
            
                return response
            
        except Exception as e:
            logger.error(f"‚ùå Erreur max: {e}")
            return f"‚ùå Erreur lors de la recherche du maximum: {str(e)}"
    
    def _handle_min(self, question: str, intention: Dict[str, Any]) -> str:
        """G√®re les questions de minimum"""
        try:
            df = self._apply_filters(self.data, intention['filters'])
            df = df[df['montant_global_estime'] > 0]  # Exclure les 0
            
            if len(df) == 0:
                return "‚ùå Aucun enregistrement ne correspond √† vos crit√®res."
            
            # D√©terminer la colonne
            if 'montant_global_estime' in df.columns:
                col = 'montant_global_estime'
            else:
                return "‚ùå Colonne non trouv√©e."
            
            min_val = df[col].min()
            min_row = df[df[col] == min_val].iloc[0]
            
            response = f"üìâ **Minimum trouv√©**\n\n"
            response += f"**Valeur minimum**: {min_val:,.2f} ‚Ç¨\n\n"
            response += f"**D√©tails du lot**:\n"
            
            if 'intitule_lot' in min_row:
                response += f"- **Intitul√©**: {min_row['intitule_lot']}\n"
            if 'groupement' in min_row:
                response += f"- **Groupement**: {min_row['groupement']}\n"
            if 'univers' in min_row:
                response += f"- **Univers**: {min_row['univers']}\n"
            if 'reference_procedure' in min_row:
                response += f"- **R√©f√©rence**: {min_row['reference_procedure']}\n"
            
            return response
            
        except Exception as e:
            logger.error(f"‚ùå Erreur min: {e}")
            return f"‚ùå Erreur lors de la recherche du minimum: {str(e)}"
    
    def _handle_list(self, question: str, intention: Dict[str, Any]) -> str:
        """G√®re les questions de liste/affichage et de recherche"""
        try:
            # V√©rifier si c'est une recherche sp√©cifique par r√©f√©rence ou intitul√©
            if self._is_search_question(question):
                search_result = self._handle_specific_search(question, intention)
                if search_result:
                    return search_result
            
            df = self._apply_filters(self.data, intention['filters'])
            
            if len(df) == 0:
                return "‚ùå Aucun enregistrement ne correspond √† vos crit√®res."
            
            filters_desc = self._describe_filters(intention['filters'])
            
            # Stocker les donn√©es pour l'affichage en tableau
            self._last_table_data = self._prepare_table_data(df)
            
            response = f"üìã **Liste des r√©sultats**\n\n"
            
            if filters_desc:
                response += f"**Filtres appliqu√©s**: {filters_desc}\n"
            
            response += f"**Nombre de r√©sultats**: {len(df)}\n\n"
            
            # Ajouter un indicateur sp√©cial pour l'affichage en tableau
            response += "```TABLEAU_STREAMLIT```\n\n"
            
            # Ajouter un r√©sum√© des premiers r√©sultats
            response += "**Aper√ßu des premiers r√©sultats**:\n\n"
            
            display_df = self._last_table_data
            for idx, row in display_df.head(5).iterrows():
                response += f"**Lot #{idx+1}**:\n"
                for col in display_df.columns:
                    if pd.notna(row[col]) and str(row[col]).strip() and str(row[col]) != "N/A":
                        response += f"  - {col}: {row[col]}\n"
                response += "\n"
            
            if len(df) > 5:
                response += f"*... et {len(df) - 5} autres r√©sultats*\n"
            
            return response
            
        except Exception as e:
            logger.error(f"‚ùå Erreur liste: {e}")
            return f"‚ùå Erreur lors de l'affichage de la liste: {str(e)}"
    
    def _handle_specific_search(self, question: str, intention: Dict[str, Any]) -> Optional[str]:
        """G√®re les recherches sp√©cifiques par r√©f√©rence ou intitul√©"""
        try:
            # Extraire le terme de recherche
            search_term = self._extract_search_term(question)
            if not search_term:
                return None
            
            # Rechercher dans les colonnes pertinentes
            search_columns = ['reference_procedure', 'intitule_lot', 'intitule_procedure']
            results = []
            
            for col in search_columns:
                if col in self.data.columns:
                    # Recherche insensible √† la casse
                    mask = self.data[col].astype(str).str.contains(search_term, case=False, na=False)
                    col_results = self.data[mask]
                    if not col_results.empty:
                        results.append((col, col_results))
            
            if not results:
                return f"‚ùå Aucun r√©sultat trouv√© pour '{search_term}'"
            
            # Combiner tous les r√©sultats
            all_results = pd.concat([df for _, df in results], ignore_index=True)
            all_results = all_results.drop_duplicates()
            
            # Stocker les donn√©es pour l'affichage en tableau
            self._last_table_data = self._prepare_table_data(all_results)
            
            response = f"üîç **R√©sultats de recherche pour '{search_term}'**\n\n"
            
            # Afficher les colonnes o√π le terme a √©t√© trouv√©
            found_in = []
            for col, df in results:
                if not df.empty:
                    col_name = col.replace('_', ' ').title()
                    found_in.append(f"{col_name} ({len(df)} r√©sultats)")
            
            response += f"**Trouv√© dans**: {', '.join(found_in)}\n"
            response += f"**Total de r√©sultats**: {len(all_results)}\n\n"
            
            # Ajouter un indicateur sp√©cial pour l'affichage en tableau
            response += "```TABLEAU_STREAMLIT```\n\n"
            
            # Ajouter un r√©sum√© des premiers r√©sultats
            response += "**Aper√ßu des r√©sultats**:\n\n"
            
            display_df = self._last_table_data
            for idx, row in display_df.head(5).iterrows():
                response += f"**Lot #{idx+1}**:\n"
                for col in display_df.columns:
                    if pd.notna(row[col]) and str(row[col]).strip() and str(row[col]) != "N/A":
                        response += f"  - {col}: {row[col]}\n"
                response += "\n"
            
            if len(all_results) > 5:
                response += f"*... et {len(all_results) - 5} autres r√©sultats*\n"
            
            return response
            
        except Exception as e:
            logger.error(f"‚ùå Erreur recherche sp√©cifique: {e}")
            return None
    
    def _extract_search_term(self, question: str) -> Optional[str]:
        """Extrait le terme de recherche de la question"""
        try:
            question_lower = question.lower()
            
            # Mots-cl√©s √† ignorer
            ignore_words = ['cherche', 'trouve', 'recherche', 'rechercher', 'pour', 'le', 'la', 'les', 'un', 'une', 'des', 'du', 'de', 'dans', 'avec']
            
            # Diviser la question en mots
            words = question_lower.split()
            
            # Trouver le mot-cl√© de recherche
            search_keyword = None
            for keyword in ['cherche', 'trouve', 'recherche', 'rechercher']:
                if keyword in words:
                    search_keyword = keyword
                    break
            
            if not search_keyword:
                return None
            
            # Extraire les mots apr√®s le mot-cl√© de recherche
            keyword_index = words.index(search_keyword)
            search_words = words[keyword_index + 1:]
            
            # Filtrer les mots √† ignorer
            search_words = [word for word in search_words if word not in ignore_words]
            
            if not search_words:
                return None
            
            # Rejoindre les mots pour former le terme de recherche
            search_term = ' '.join(search_words)
            
            # Nettoyer le terme
            search_term = search_term.strip('.,!?')
            
            return search_term if search_term else None
            
        except Exception as e:
            logger.error(f"‚ùå Erreur extraction terme recherche: {e}")
            return None
    
    def _is_search_question(self, question: str) -> bool:
        """D√©termine si c'est une question de recherche sp√©cifique"""
        question_lower = question.lower()
        
        # Mots-cl√©s de recherche
        search_keywords = ['cherche', 'trouve', 'recherche', 'rechercher']
        
        # V√©rifier si la question contient un mot-cl√© de recherche
        if not any(keyword in question_lower for keyword in search_keywords):
            return False
        
        # Extraire le terme de recherche
        search_term = self._extract_search_term(question)
        if not search_term:
            return False
        
        # V√©rifier si c'est une r√©f√©rence de proc√©dure (format: 2024-R059, 24AOOSIA, etc.)
        ref_pattern = r'^\d{4}-[A-Z]\d{2,3}$|^\d{2}[A-Z]{2,}\d{2,}$|^[A-Z]\d{2,}$'
        if re.match(ref_pattern, search_term.upper()):
            return True
        
        # V√©rifier si c'est un terme de recherche court (probablement une recherche sp√©cifique)
        if len(search_term.split()) <= 3:
            return True
        
        return False
    
    def _should_skip_filters_for_search(self, question: str) -> bool:
        """D√©termine si on doit ignorer les filtres g√©n√©raux pour une recherche sp√©cifique"""
        return self._is_search_question(question)
    
    def _prepare_table_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """Pr√©pare les donn√©es pour l'affichage en tableau"""
        try:
            # S√©lectionner les colonnes importantes
            important_cols = ['intitule_lot', 'groupement', 'univers', 'montant_global_estime', 
                            'statut', 'reference_procedure', 'date_limite', 'intitule_procedure']
            
            cols_to_show = [col for col in important_cols if col in df.columns]
            display_df = df[cols_to_show].copy()
            
            # Renommer les colonnes pour l'affichage
            display_df.columns = [col.replace('_', ' ').title() for col in display_df.columns]
            
            # Formater les montants
            if 'Montant Global Estime' in display_df.columns:
                display_df['Montant Global Estime'] = display_df['Montant Global Estime'].apply(
                    lambda x: f"{x:,.2f} ‚Ç¨" if pd.notna(x) and x != 0 else "N/A"
                )
            
            # Formater les dates
            if 'Date Limite' in display_df.columns:
                display_df['Date Limite'] = display_df['Date Limite'].apply(
                    lambda x: x.strftime('%d/%m/%Y') if pd.notna(x) else "N/A"
                )
            
            return display_df
            
        except Exception as e:
            logger.error(f"‚ùå Erreur pr√©paration tableau: {e}")
            return df.head(10)
    
    def get_last_table_data(self) -> Optional[pd.DataFrame]:
        """Retourne les derni√®res donn√©es pr√©par√©es pour l'affichage en tableau"""
        return getattr(self, '_last_table_data', None)
    
    def _handle_distribution(self, question: str, intention: Dict[str, Any]) -> str:
        """G√®re les questions de r√©partition/distribution"""
        try:
            df = self._apply_filters(self.data, intention['filters'])
            
            if len(df) == 0:
                return "‚ùå Aucun enregistrement ne correspond √† vos crit√®res."
            
            # D√©terminer la colonne de regroupement
            group_col = intention['aggregation']
            if not group_col:
                # Essayer de d√©tecter automatiquement
                if 'univers' in question.lower():
                    group_col = 'univers'
                elif 'groupement' in question.lower():
                    group_col = 'groupement'
                elif 'statut' in question.lower():
                    group_col = 'statut'
                elif 'segment' in question.lower():
                    group_col = 'segment'
                else:
                    group_col = 'univers'  # Par d√©faut
            
            if group_col not in df.columns:
                return f"‚ùå Colonne '{group_col}' non trouv√©e."
            
            # Calcul de la distribution
            distribution = df[group_col].value_counts()
            total = len(df)
            
            response = f"üìä **R√©partition par {group_col.replace('_', ' ').title()}**\n\n"
            response += f"**Total**: {total} lots\n\n"
            
            for val, count in distribution.items():
                if val and str(val).strip():
                    percentage = (count / total) * 100
                    response += f"- **{val}**: {count} lots ({percentage:.1f}%)\n"
            
            # Ajouter des statistiques de montant si disponible
            if 'montant_global_estime' in df.columns:
                response += f"\n**Montants par {group_col.replace('_', ' ').title()}**:\n\n"
                grouped_amounts = df.groupby(group_col)['montant_global_estime'].agg(['sum', 'mean', 'count'])
                
                for val, row in grouped_amounts.iterrows():
                    if val and str(val).strip():
                        response += f"- **{val}**:\n"
                        response += f"  - Total: {row['sum']:,.2f} ‚Ç¨\n"
                        response += f"  - Moyenne: {row['mean']:,.2f} ‚Ç¨\n"
                        response += f"  - Lots: {int(row['count'])}\n"
            
            return response
            
        except Exception as e:
            logger.error(f"‚ùå Erreur distribution: {e}")
            return f"‚ùå Erreur lors du calcul de la distribution: {str(e)}"
    
    def _handle_comparison(self, question: str, intention: Dict[str, Any]) -> str:
        """G√®re les questions de comparaison"""
        try:
            # Comparaison entre groupements ou univers
            compare_col = None
            if 'groupement' in question.lower():
                compare_col = 'groupement'
            elif 'univers' in question.lower():
                compare_col = 'univers'
            
            if not compare_col or compare_col not in self.data.columns:
                return "‚ùå Impossible de d√©terminer quoi comparer."
            
            # Statistiques par groupe
            grouped = self.data.groupby(compare_col).agg({
                'montant_global_estime': ['sum', 'mean', 'count'],
                'id': 'count'
            }).round(2)
            
            grouped.columns = ['Montant Total', 'Montant Moyen', 'Count_montant', 'Nombre Lots']
            grouped = grouped.sort_values('Montant Total', ascending=False)
            
            response = f"‚öñÔ∏è **Comparaison par {compare_col.replace('_', ' ').title()}**\n\n"
            
            for idx, row in grouped.iterrows():
                if idx and str(idx).strip():
                    response += f"**{idx}**:\n"
                    response += f"  - Montant total: {row['Montant Total']:,.2f} ‚Ç¨\n"
                    response += f"  - Montant moyen: {row['Montant Moyen']:,.2f} ‚Ç¨\n"
                    response += f"  - Nombre de lots: {int(row['Nombre Lots'])}\n\n"
            
            return response
            
        except Exception as e:
            logger.error(f"‚ùå Erreur comparaison: {e}")
            return f"‚ùå Erreur lors de la comparaison: {str(e)}"
    
    def _handle_analysis(self, question: str, intention: Dict[str, Any]) -> str:
        """G√®re les demandes d'analyse globale"""
        try:
            df = self._apply_filters(self.data, intention['filters'])
            
            if len(df) == 0:
                return "‚ùå Aucun enregistrement ne correspond √† vos crit√®res."
            
            response = f"üìä **Analyse Compl√®te**\n\n"
            
            # Statistiques g√©n√©rales
            response += f"### üìà Vue d'ensemble\n"
            response += f"- **Nombre total de lots**: {len(df)}\n"
            
            if 'montant_global_estime' in df.columns:
                total_montant = df['montant_global_estime'].sum()
                avg_montant = df['montant_global_estime'].mean()
                response += f"- **Montant total**: {total_montant:,.2f} ‚Ç¨\n"
                response += f"- **Montant moyen**: {avg_montant:,.2f} ‚Ç¨\n"
            
            # Par univers
            if 'univers' in df.columns:
                response += f"\n### üåç Par Univers\n"
                univers_dist = df['univers'].value_counts().head(5)
                for univ, count in univers_dist.items():
                    if univ and str(univ).strip():
                        response += f"- **{univ}**: {count} lots\n"
            
            # Par groupement
            if 'groupement' in df.columns:
                response += f"\n### üè¢ Par Groupement\n"
                groupe_dist = df['groupement'].value_counts().head(5)
                for grp, count in groupe_dist.items():
                    if grp and str(grp).strip():
                        response += f"- **{grp}**: {count} lots\n"
            
            # Par statut
            if 'statut' in df.columns:
                response += f"\n### ‚ö° Par Statut\n"
                statut_dist = df['statut'].value_counts()
                for stat, count in statut_dist.items():
                    if stat and str(stat).strip():
                        response += f"- **{stat}**: {count} lots\n"
            
            return response
            
        except Exception as e:
            logger.error(f"‚ùå Erreur analyse: {e}")
            return f"‚ùå Erreur lors de l'analyse: {str(e)}"
    
    def _handle_expiring_lots(self, question: str, intention: Dict[str, Any]) -> str:
        """G√®re les questions sur les lots dont la fin de march√© approche"""
        try:
            from datetime import timedelta
            
            # Appliquer les filtres de base
            df = self._apply_filters(self.data, intention['filters'])
            
            if len(df) == 0:
                return "‚ùå Aucun enregistrement ne correspond √† vos crit√®res."
            
            # D√©terminer la p√©riode d'alerte (par d√©faut 3 mois)
            question_lower = question.lower()
            
            # Extraire le nombre de mois si mentionn√©
            import re
            months_match = re.search(r'(\d+)\s*mois', question_lower)
            if months_match:
                months_threshold = int(months_match.group(1))
            elif 'semaine' in question_lower:
                weeks_match = re.search(r'(\d+)\s*semaine', question_lower)
                months_threshold = int(weeks_match.group(1)) / 4 if weeks_match else 0.25
            elif 'jour' in question_lower:
                days_match = re.search(r'(\d+)\s*jour', question_lower)
                months_threshold = int(days_match.group(1)) / 30 if days_match else 0.1
            else:
                months_threshold = 3  # Par d√©faut : 3 mois
            
            # Calculer la date limite
            today = pd.Timestamp.now()
            threshold_date = today + timedelta(days=months_threshold * 30)
            
            # Diagnostic des colonnes de dates disponibles
            date_columns = ['fin_avec_reconduction', 'fin_sans_reconduction', 'date_limite', 'date_attribution']
            available_date_cols = [col for col in date_columns if col in df.columns]
            
            # Analyser les donn√©es de dates
            date_analysis = {}
            for col in available_date_cols:
                non_null_count = df[col].notna().sum()
                date_analysis[col] = {
                    'total': len(df),
                    'non_null': non_null_count,
                    'null_percent': (1 - non_null_count / len(df)) * 100 if len(df) > 0 else 100
                }
            
            # Utiliser la colonne avec le plus de donn√©es valides
            best_date_col = None
            max_valid_dates = 0
            
            for col in available_date_cols:
                if date_analysis[col]['non_null'] > max_valid_dates:
                    max_valid_dates = date_analysis[col]['non_null']
                    best_date_col = col
            
            if not best_date_col or max_valid_dates == 0:
                # Aucune colonne de date valide, utiliser date_limite comme fallback
                if 'date_limite' in df.columns:
                    best_date_col = 'date_limite'
                else:
                    return f"""‚ùå **Probl√®me de donn√©es d√©tect√©**

**Diagnostic des colonnes de dates :**
{chr(10).join([f"- {col}: {info['non_null']}/{info['total']} ({info['null_percent']:.1f}% vides)" for col, info in date_analysis.items()])}

**Recommandations :**
1. V√©rifiez que les colonnes 'fin_avec_reconduction' et 'fin_sans_reconduction' contiennent des dates
2. Assurez-vous que les dates sont au format YYYY-MM-DD
3. Importez des donn√©es avec des dates de fin de march√© valides

**Colonnes disponibles :** {', '.join(df.columns.tolist())}"""
            
            # Convertir la colonne de date en datetime
            df_temp = df.copy()
            df_temp[best_date_col] = pd.to_datetime(df_temp[best_date_col], errors='coerce')
            
            # Filtrer les lots valides (avec dates non nulles)
            valid_dates_mask = df_temp[best_date_col].notna()
            df_with_dates = df_temp[valid_dates_mask].copy()
            
            if len(df_with_dates) == 0:
                return f"""‚ùå **Aucune date valide trouv√©e**

**Colonne analys√©e :** {best_date_col}
**Total de lots :** {len(df)}
**Lots avec dates valides :** 0

**Exemples de donn√©es dans cette colonne :**
{df[best_date_col].head(10).tolist()}

**V√©rifiez le format des dates dans votre base de donn√©es.**"""
            
            # Filtrer les lots qui expirent bient√¥t
            expiring_mask = (df_with_dates[best_date_col] >= today) & (df_with_dates[best_date_col] <= threshold_date)
            expiring_lots = df_with_dates[expiring_mask].copy()
            
            if len(expiring_lots) == 0:
                filters_desc = self._describe_filters(intention['filters'])
                response = f"‚úÖ **Bonne nouvelle !**\n\n"
                if filters_desc:
                    response += f"**Filtres appliqu√©s**: {filters_desc}\n\n"
                response += f"Aucun lot ne se termine dans les **{months_threshold:.0f} mois** √† venir.\n\n"
                response += f"üìä **Statistiques :**\n"
                response += f"- Total de lots analys√©s: {len(df)}\n"
                response += f"- Lots avec dates valides: {len(df_with_dates)}\n"
                response += f"- Colonne utilis√©e: {best_date_col}\n"
                response += f"- P√©riode d'alerte: {today.strftime('%d/%m/%Y')} ‚Üí {threshold_date.strftime('%d/%m/%Y')}"
                return response
            
            # Ajouter les colonnes calcul√©es
            expiring_lots['jours_restants'] = (expiring_lots[best_date_col] - today).dt.days
            expiring_lots['date_fin'] = expiring_lots[best_date_col]
            expiring_lots['type_fin'] = best_date_col.replace('fin_', '').replace('_', ' ').title()
            
            # Trier par jours restants
            expiring_lots = expiring_lots.sort_values('jours_restants')
            
            # Pr√©parer le tableau pour affichage
            self._last_table_data = self._prepare_expiring_table_data(expiring_lots)
            
            # Cr√©er la r√©ponse
            filters_desc = self._describe_filters(intention['filters'])
            
            response = f"‚ö†Ô∏è **Lots dont la fin de march√© approche**\n\n"
            
            if filters_desc:
                response += f"**Filtres appliqu√©s**: {filters_desc}\n"
            
            response += f"**P√©riode d'alerte**: {months_threshold:.0f} mois ({int(months_threshold * 30)} jours)\n"
            response += f"**Colonne utilis√©e**: {best_date_col}\n"
            response += f"**Nombre de lots concern√©s**: {len(expiring_lots)}\n\n"
            
            # Cat√©goriser par urgence
            urgent = expiring_lots[expiring_lots['jours_restants'] <= 30]
            warning = expiring_lots[(expiring_lots['jours_restants'] > 30) & (expiring_lots['jours_restants'] <= 60)]
            normal = expiring_lots[expiring_lots['jours_restants'] > 60]
            
            if len(urgent) > 0:
                response += f"üî¥ **Urgent** (‚â§ 30 jours): {len(urgent)} lots\n"
            if len(warning) > 0:
                response += f"üü† **Attention** (31-60 jours): {len(warning)} lots\n"
            if len(normal) > 0:
                response += f"üü° **√Ä surveiller** (> 60 jours): {len(normal)} lots\n"
            
            response += "\n```TABLEAU_STREAMLIT```\n\n"
            
            # Ajouter un r√©sum√© des premiers lots
            response += "**Aper√ßu des lots les plus proches**:\n\n"
            
            display_df = self._last_table_data
            for idx, row in display_df.head(5).iterrows():
                days_left = expiring_lots.iloc[idx]['jours_restants']
                urgency = "üî¥" if days_left <= 30 else "üü†" if days_left <= 60 else "üü°"
                
                response += f"{urgency} **Lot #{idx+1}** (J-{days_left}):\n"
                for col in display_df.columns:
                    if pd.notna(row[col]) and str(row[col]).strip() and str(row[col]) != "N/A":
                        response += f"  - {col}: {row[col]}\n"
                response += "\n"
            
            if len(expiring_lots) > 5:
                response += f"*... et {len(expiring_lots) - 5} autres lots*\n"
            
            return response
            
        except Exception as e:
            logger.error(f"‚ùå Erreur gestion lots expirants: {e}")
            import traceback
            traceback.print_exc()
            return f"‚ùå Erreur lors de la recherche des lots expirants: {str(e)}"
    
    def _prepare_expiring_table_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """Pr√©pare les donn√©es des lots expirants pour l'affichage en tableau"""
        try:
            # S√©lectionner les colonnes importantes
            important_cols = ['intitule_lot', 'groupement', 'univers', 'montant_global_estime', 
                            'statut', 'reference_procedure', 'date_fin', 'jours_restants', 'type_fin']
            
            cols_to_show = [col for col in important_cols if col in df.columns]
            display_df = df[cols_to_show].copy()
            
            # Renommer les colonnes pour l'affichage
            column_rename = {
                'intitule_lot': 'Intitul√© Lot',
                'groupement': 'Groupement',
                'univers': 'Univers',
                'montant_global_estime': 'Montant Estim√©',
                'statut': 'Statut',
                'reference_procedure': 'R√©f√©rence',
                'date_fin': 'Date de Fin',
                'jours_restants': 'Jours Restants',
                'type_fin': 'Type de Fin'
            }
            
            display_df = display_df.rename(columns=column_rename)
            
            # Formater les montants
            if 'Montant Estim√©' in display_df.columns:
                display_df['Montant Estim√©'] = display_df['Montant Estim√©'].apply(
                    lambda x: f"{x:,.2f} ‚Ç¨" if pd.notna(x) and x != 0 else "N/A"
                )
            
            # Formater les dates
            if 'Date de Fin' in display_df.columns:
                display_df['Date de Fin'] = display_df['Date de Fin'].apply(
                    lambda x: x.strftime('%d/%m/%Y') if pd.notna(x) else "N/A"
                )
            
            # Ajouter un indicateur d'urgence
            if 'Jours Restants' in display_df.columns:
                display_df['Urgence'] = display_df['Jours Restants'].apply(
                    lambda x: "üî¥ Urgent" if x <= 30 else "üü† Attention" if x <= 60 else "üü° √Ä surveiller"
                )
                display_df['Jours Restants'] = display_df['Jours Restants'].apply(
                    lambda x: f"J-{int(x)}" if pd.notna(x) else "N/A"
                )
            
            return display_df
            
        except Exception as e:
            logger.error(f"‚ùå Erreur pr√©paration tableau expirants: {e}")
            return df.head(10)
    
    def _handle_conversation(self, question: str) -> str:
        """G√®re les questions conversationnelles"""
        question_lower = question.lower()
        
        if any(word in question_lower for word in ['bonjour', 'salut', 'hello', 'hi']):
            return """üëã **Bonjour ! Je suis votre assistant IA avanc√© pour la veille concurrentielle.**

Je peux r√©pondre √† toutes vos questions sur la base de donn√©es :

üî¢ **Statistiques**:
- "Combien de lots par univers ?"
- "Quelle est la somme totale des budgets ?"
- "Quel est le montant moyen pour le RESAH ?"

üìã **Listes et filtres**:
- "Montre-moi les lots du RESAH en informatique"
- "Liste les lots de plus de 100 000 ‚Ç¨"
- "Affiche les appels d'offres en cours"

‚è∞ **Fins de march√©**:
- "Quels lots se terminent bient√¥t ?"
- "Montre les march√©s qui expirent dans 6 mois"
- "Lots dont la fin de march√© approche"
- "Affiche les lots du RESAH qui se terminent bient√¥t"

üìä **Analyses**:
- "Analyse la r√©partition par groupement"
- "Compare les univers"
- "Donne-moi les statistiques compl√®tes"

‚öñÔ∏è **Comparaisons**:
- "Compare RESAH et UNIHA"
- "Quelle est la diff√©rence entre les univers ?"

üîó **Conversations contextuelles**:
- Posez une premi√®re question, puis encha√Ænez !
- "Montre les lots du RESAH" ‚Üí "Et pour l'UNIHA ?"
- "Combien de lots en informatique ?" ‚Üí "Et en m√©dical ?"

N'h√©sitez pas √† poser n'importe quelle question ! üòä"""
        
        elif 'merci' in question_lower:
            return "üòä **Je vous en prie !** N'h√©sitez pas si vous avez d'autres questions sur la base de donn√©es."
        
        elif any(word in question_lower for word in ['au revoir', 'bye', 'adieu']):
            return "üëã **Au revoir !** √Ä bient√¥t pour d'autres analyses !"
        
        elif any(phrase in question_lower for phrase in ['historique', 'histoire', 'conversation pr√©c√©dente', 'ce qu', 'on a dit']):
            return self.display_conversation_summary()
        
        elif any(phrase in question_lower for phrase in ['diagnostic', 'diagnostique', '√©tat des donn√©es', 'qualit√© des donn√©es', 'probl√®me de donn√©es']):
            return self._handle_data_diagnostic(question)
        
        else:
            return self._handle_general(question, {})
    
    def _handle_general(self, question: str, intention: Dict[str, Any]) -> str:
        """G√®re les questions g√©n√©rales ou non reconnues"""
        return f"""ü§î **Je ne suis pas certain de bien comprendre votre question.**

**Voici quelques exemples de questions que vous pouvez poser**:

üìä **Statistiques**:
- "Combien y a-t-il de lots au total ?"
- "Quelle est la somme des budgets ?"
- "Quel est le montant moyen par univers ?"

üîç **Recherche et filtrage**:
- "Montre-moi les lots du RESAH"
- "Liste les lots en informatique"
- "Affiche les lots de plus de 100 000 ‚Ç¨"

‚è∞ **Fins de march√©**:
- "Quels lots se terminent bient√¥t ?"
- "Montre les march√©s qui expirent dans 6 mois"
- "Affiche les lots du RESAH qui se terminent bient√¥t"

üìà **Analyses**:
- "R√©partition par groupement"
- "Compare les univers"
- "Analyse compl√®te des donn√©es"

üí° **Astuce**: Essayez d'√™tre plus pr√©cis dans votre question !

*Votre question*: "{question}"
"""
    
    def _describe_filters(self, filters: Dict[str, Any]) -> str:
        """D√©crit les filtres appliqu√©s en langage naturel"""
        if not filters:
            return ""
        
        descriptions = []
        
        for key, value in filters.items():
            if key == 'groupement':
                descriptions.append(f"Groupement: {value}")
            elif key == 'univers':
                descriptions.append(f"Univers: {value}")
            elif key == 'statut':
                descriptions.append(f"Statut: {value}")
            elif key == 'year':
                descriptions.append(f"Ann√©e: {value}")
            elif key == 'montant_min':
                descriptions.append(f"Montant ‚â• {value:,.0f} ‚Ç¨")
            elif key == 'montant_max':
                descriptions.append(f"Montant ‚â§ {value:,.0f} ‚Ç¨")
            elif key == 'montant_approx':
                descriptions.append(f"Montant ‚âà {value:,.0f} ‚Ç¨")
        
        return ", ".join(descriptions)
    
    def _update_average_response_time(self, elapsed_time: float):
        """Met √† jour le temps de r√©ponse moyen"""
        total = self.performance_metrics['total_questions']
        current_avg = self.performance_metrics['average_response_time']
        
        if total == 1:
            self.performance_metrics['average_response_time'] = elapsed_time
        else:
            self.performance_metrics['average_response_time'] = (
                (current_avg * (total - 1) + elapsed_time) / total
            )
    
    def get_performance_metrics(self) -> Dict[str, Any]:
        """Retourne les m√©triques de performance"""
        metrics = self.performance_metrics.copy()
        
        if metrics['total_questions'] > 0:
            metrics['success_rate'] = metrics['successful_answers'] / metrics['total_questions']
            metrics['cache_hit_rate'] = metrics['cache_hits'] / (metrics['cache_hits'] + metrics['cache_misses']) if (metrics['cache_hits'] + metrics['cache_misses']) > 0 else 0
        else:
            metrics['success_rate'] = 0
            metrics['cache_hit_rate'] = 0
        
        return metrics
    
    def clear_conversation_memory(self):
        """Efface l'historique de conversation et le cache"""
        self.conversation_history = []
        self.cache = {}
        logger.info("üóëÔ∏è M√©moire de conversation effac√©e")
    
    def get_conversation_history(self) -> List[Dict[str, Any]]:
        """Retourne l'historique de conversation"""
        return self.conversation_history
    
    def display_conversation_summary(self) -> str:
        """Affiche un r√©sum√© de l'historique de conversation"""
        if not self.conversation_history:
            return "üì≠ Aucune conversation enregistr√©e."
        
        response = f"üìú **Historique de conversation** ({len(self.conversation_history)} √©changes)\n\n"
        
        for i, exchange in enumerate(self.conversation_history[-10:], 1):  # Derniers 10 √©changes
            timestamp = exchange.get('timestamp', datetime.now()).strftime('%H:%M:%S')
            question = exchange.get('question', '')
            is_contextual = exchange.get('is_contextual', False)
            
            contextual_icon = "üîó" if is_contextual else "üí¨"
            response += f"{contextual_icon} **[{timestamp}]** {question}\n"
        
        if len(self.conversation_history) > 10:
            response += f"\n*... et {len(self.conversation_history) - 10} √©changes plus anciens*"
        
        return response
    
    def _handle_data_diagnostic(self, question: str) -> str:
        """G√®re les demandes de diagnostic des donn√©es"""
        try:
            if not self.initialized or self.data is None:
                return "‚ùå Aucune donn√©e charg√©e pour le diagnostic."
            
            response = "üîç **Diagnostic des donn√©es**\n\n"
            
            # Informations g√©n√©rales
            response += f"**Total d'enregistrements**: {len(self.data)}\n"
            response += f"**Nombre de colonnes**: {len(self.data.columns)}\n\n"
            
            # Analyse des colonnes de dates
            date_columns = ['fin_avec_reconduction', 'fin_sans_reconduction', 'date_limite', 'date_attribution']
            available_date_cols = [col for col in date_columns if col in self.data.columns]
            
            response += "**üìÖ Analyse des colonnes de dates :**\n"
            for col in available_date_cols:
                non_null = self.data[col].notna().sum()
                null_percent = (1 - non_null / len(self.data)) * 100 if len(self.data) > 0 else 100
                response += f"- **{col}**: {non_null}/{len(self.data)} ({null_percent:.1f}% vides)\n"
            
            if not available_date_cols:
                response += "- ‚ùå Aucune colonne de date trouv√©e\n"
            
            response += "\n**üìä Exemples de donn√©es de dates :**\n"
            for col in available_date_cols[:2]:  # Limiter √† 2 colonnes
                sample_data = self.data[col].dropna().head(5).tolist()
                response += f"- **{col}**: {sample_data}\n"
            
            # Analyse des colonnes importantes
            important_cols = ['groupement', 'univers', 'statut', 'montant_global_estime']
            response += "\n**üìã Analyse des colonnes importantes :**\n"
            for col in important_cols:
                if col in self.data.columns:
                    non_null = self.data[col].notna().sum()
                    null_percent = (1 - non_null / len(self.data)) * 100 if len(self.data) > 0 else 100
                    unique_vals = self.data[col].nunique()
                    response += f"- **{col}**: {non_null}/{len(self.data)} ({null_percent:.1f}% vides), {unique_vals} valeurs uniques\n"
                else:
                    response += f"- **{col}**: ‚ùå Colonne manquante\n"
            
            # Recommandations
            response += "\n**üí° Recommandations :**\n"
            
            if not available_date_cols:
                response += "- ‚ùå **CRITIQUE**: Aucune colonne de date trouv√©e. Ajoutez des colonnes de dates valides.\n"
            else:
                best_date_col = None
                max_valid = 0
                for col in available_date_cols:
                    valid_count = self.data[col].notna().sum()
                    if valid_count > max_valid:
                        max_valid = valid_count
                        best_date_col = col
                
                if best_date_col and max_valid > 0:
                    response += f"- ‚úÖ Colonne de date recommand√©e: **{best_date_col}** ({max_valid} dates valides)\n"
                else:
                    response += "- ‚ùå Aucune colonne de date avec des donn√©es valides\n"
            
            # V√©rifier les montants
            if 'montant_global_estime' in self.data.columns:
                montant_non_null = self.data['montant_global_estime'].notna().sum()
                if montant_non_null == 0:
                    response += "- ‚ö†Ô∏è Colonne 'montant_global_estime' vide - ajoutez des montants\n"
                else:
                    response += f"- ‚úÖ Montants disponibles: {montant_non_null} enregistrements\n"
            
            # V√©rifier les groupements
            if 'groupement' in self.data.columns:
                groupements = self.data['groupement'].value_counts()
                response += f"- ‚úÖ Groupements trouv√©s: {', '.join(groupements.head(3).index.tolist())}\n"
            
            return response
            
        except Exception as e:
            logger.error(f"‚ùå Erreur diagnostic: {e}")
            return f"‚ùå Erreur lors du diagnostic: {str(e)}"
    
    def get_model_status(self) -> Dict[str, bool]:
        """Retourne le statut des mod√®les (pour compatibilit√© avec l'app)"""
        return {
            'bert_model': self.initialized,
            'embedding_model': self.initialized,
            'nlp_model': self.initialized,
            'classifier': self.initialized
        }
